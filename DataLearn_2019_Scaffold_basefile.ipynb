{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataLearn 2019 - Scaffold.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/debbysonino/LamasDataHack/blob/master/DataLearn_2019_Scaffold_basefile.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTnHVMK-wyjz",
        "colab_type": "text"
      },
      "source": [
        "&nbsp; ![alt text](https://s3.amazonaws.com/monday.com/static/svg/monday-logos/monday-footer-logo.svg)\n",
        "\n",
        "#Model scaffold\n",
        "This notebook is intended to get you up and running faster.\n",
        "\n",
        "It has the basic scaffold of an ML model, including:\n",
        "* Data loading\n",
        "* Feature extraction\n",
        "* Columns transformation\n",
        "* Training\n",
        "* Evaluating\n",
        "* Submitting results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhDZdkDTjyf-",
        "colab_type": "text"
      },
      "source": [
        "###Getting our depnedncies (and data!)\n",
        "First we'll import our relevant libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gao6_ydqMgBS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# General DS libraries we are going to need\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import timedelta\n",
        "\n",
        "# Importing our base model\n",
        "# [REDACTED ML MODEL USED]\n",
        "\n",
        "# Imports for working with our large dataset\n",
        "from sklearn.utils.random import sample_without_replacement\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# We need those for data manipulation and getting our features ready for the model\n",
        "from sklearn.preprocessing import OneHotEncoder, Normalizer, Binarizer\n",
        "from sklearn.compose import make_column_transformer\n",
        "\n",
        "# These can be used to measure our model's performance\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Ignore DataFrame assignment warnings\n",
        "pd.options.mode.chained_assignment = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jNoDkmNAsCaY"
      },
      "source": [
        "\n",
        "We set a few constants to use later on for sampeling and running the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JhqmBDsksCaa",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Model parameters { run: \"auto\" }\n",
        "# n_neighbors = 7 #@param {type:\"slider\", min:1, max:30, step:1}\n",
        "group_name = \"Lamassim\" #@param {type:\"string\"}\n",
        "samples_num = 1360000 #@param {type:\"slider\", min:0, max:1500000, step:10000}\n",
        "n_jobs = -1 #@param {type:\"slider\", min:-1, max:32, step:1}\n",
        "path_prefix = \"https://storage.googleapis.com/mondaycom-datahack/final_sets\" #@param [\"https://storage.googleapis.com/mondaycom-datahack/final_sets\", \"https://mondaycom-datahack.s3.amazonaws.com/final_sets\"] {allow-input: true}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DpkqHB9lsUmQ"
      },
      "source": [
        "Next we'll load all the different parts of our dataset\n",
        "\n",
        "<br/>\n",
        "\n",
        "_Our use my data loading [snippet](https://colab.research.google.com/drive/1_Y-sZ5eHIDlDUMuLCwfnbuJdLh0DTXmO#scrollTo=5HGlaJTEAYJu&line=23&uniqifier=1)!_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2x0lOgBZRP_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# We define the datasets we want to load\n",
        "datasets = ('accounts', 'users', 'events', 'subscriptions')\n",
        "source_prefix = 'https://storage.googleapis.com/mondaycom-datahack/final_sets/'\n",
        "\n",
        "local_dir = './datasets/datahack/'\n",
        "file_prefix = 'train_'\n",
        "file_suffix = ''\n",
        "file_extension = 'csv'\n",
        "\n",
        "# We create a directory for the datasets if it doesn't exist\n",
        "if not os.path.exists(local_dir):\n",
        "    os.makedirs(local_dir)\n",
        "\n",
        "# For each dataset we want, we check if we already downloaded it and fix it if we didn't\n",
        "for dataset in datasets:\n",
        "  if not os.path.isfile('{}{}{}{}.{}'.format(local_dir, file_prefix, dataset, file_suffix, file_extension)):\n",
        "    !curl {source_prefix}{file_prefix}{dataset}{file_suffix}.{file_extension} --output {local_dir}{file_prefix}{dataset}{file_suffix}.{file_extension}\n",
        "\n",
        "  # Load the datasets into a DataFrame using pandas\n",
        "  globals()['{}{}'.format(file_prefix, dataset)] = pd.read_csv('{}{}{}{}.{}'.format(local_dir, file_prefix, dataset, file_suffix, file_extension), low_memory=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdEFqnpfKjmk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# We define the datasets we want to load\n",
        "datasets = ('accounts', 'users', 'events', 'subscriptions')\n",
        "source_prefix = 'https://storage.googleapis.com/mondaycom-datahack/final_sets/'\n",
        "\n",
        "local_dir = './datasets/datahack/'\n",
        "file_prefix = 'test_'\n",
        "file_suffix = ''\n",
        "file_extension = 'csv'\n",
        "\n",
        "# We create a directory for the datasets if it doesn't exist\n",
        "if not os.path.exists(local_dir):\n",
        "    os.makedirs(local_dir)\n",
        "\n",
        "# For each dataset we want, we check if we already downloaded it and fix it if we didn't\n",
        "for dataset in datasets:\n",
        "  if not os.path.isfile('{}{}{}{}.{}'.format(local_dir, file_prefix, dataset, file_suffix, file_extension)):\n",
        "    !curl {source_prefix}{file_prefix}{dataset}{file_suffix}.{file_extension} --output {local_dir}{file_prefix}{dataset}{file_suffix}.{file_extension}\n",
        "\n",
        "  # Load the datasets into a DataFrame using pandas\n",
        "  globals()['{}{}'.format(file_prefix, dataset)] = pd.read_csv('{}{}{}{}.{}'.format(local_dir, file_prefix, dataset, file_suffix, file_extension), low_memory=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yh1wGtOsUcnf",
        "colab_type": "text"
      },
      "source": [
        "We need to add our test sets to our train sets and work on both at the same time.\n",
        "\n",
        "We'll split them back up before training and inference."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNcD_YSBUbiY",
        "colab_type": "code",
        "outputId": "8d226131-d348-4857-e9fb-651c1274abc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "accounts = train_accounts.append(test_accounts)\n",
        "users = train_users.append(test_users)\n",
        "events = train_events.append(test_events)\n",
        "subscriptions = train_subscriptions.append(test_subscriptions)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:6692: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
            "of pandas will change to not sort by default.\n",
            "\n",
            "To accept the future behavior, pass 'sort=False'.\n",
            "\n",
            "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
            "\n",
            "  sort=sort)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jo5vLhgAlY-K",
        "colab_type": "text"
      },
      "source": [
        "###Feature engineering\n",
        "In this block we add a new feature of `[REDACTED]` extracted from the user `[REDACTED]`\n",
        "\n",
        "We also seperate all the `[REDACTED]` users into a different DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ou0AYsbL_406",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "users['[REDACTED]'] = users['REDACTED'].apply(lambda x: \"[REDACTED]\")\n",
        "[REDACTED] = users[users[\"[REDACTED]\"] == \"[REDACTED]\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6VUhsrzlvES",
        "colab_type": "text"
      },
      "source": [
        "Let's enrich our data a bit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f9X2owrCpl0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accounts[\"numuser\"]=users.groupby(\"account_id\").user_id.size()\n",
        "accounts[\"numisadmin\"]=users.groupby(\"account_id\").is_admin.sum()\n",
        "accounts[\"numenabled\"]=users.groupby(\"account_id\").enabled.sum()\n",
        "accounts[\"numpending\"]=users.groupby(\"account_id\").pending.sum()\n",
        "accounts[\"numcountry\"]=users.groupby(\"account_id\").country.count()\n",
        "accounts[\"numregion\"]=users.groupby(\"account_id\").region.count()\n",
        "accounts[\"numrcity\"]=users.groupby(\"account_id\").city.count()\n",
        "accounts[\"numphoto\"]=users.groupby(\"account_id\").has_photo.sum()\n",
        "accounts[\"nummos\"]=users.groupby(\"account_id\").os.count()\n",
        "accounts[\"nummobile\"]=users.groupby(\"account_id\").device.count()\n",
        "accounts[\"nummobile2\"]=users[users[\"device\"]==\"mobile\"].groupby(\"account_id\").device.count()\n",
        "accounts[\"numchrome\"]=users[users[\"browser\"]==\"chrome\"].groupby(\"account_id\").browser.count()\n",
        "#accounts[\"vetekuser\"]=users.groupby(\"account_id\").created_at.min()\n",
        "#accounts[\"vetekactive\"]=users.groupby(\"account_id\").became_active_at.min()\n",
        "\n",
        "\n",
        "#accounts[\"vetekuser\"]=users.groupby(\"account_id\").created_at.min()\n",
        "#accounts[\"vetekactive\"]=users.groupby(\"account_id\").became_active_at.min()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28hS7VxA6utB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "outputId": "06ee3cca-0656-4886-8b74-caa1ad985c30"
      },
      "source": [
        "\n",
        "accounts[\"nummobile2\"]=users[users[device==\"mobile\"].groupby(\"account_id\").device.count()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-84332f315bfc>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    accounts[\"nummobile2\"]=users[users[device==\"mobile\"].groupby(\"account_id\").device.count()\u001b[0m\n\u001b[0m                                                                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-u2yzKUsKqsa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_features=accounts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moN6itpxQAGi",
        "colab_type": "code",
        "outputId": "1854f53c-e13a-4e0c-dcc1-2e0def1b3a13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "all_features[all_features['lead_score'].isna()].shape[0]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "71683"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SngUmaPImHZF",
        "colab_type": "text"
      },
      "source": [
        "###Data preperation\n",
        "After we created our raw features we need to make sure the fit the way our ML model expects to receive them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-KJGAevD0iT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We map our features into different types\n",
        "categorical_features = ['country', 'device',  'industry','os', 'payment_currency','plan_id', 'region','user_goal',\n",
        "                       'utm_cluster_id','team_size' ]\n",
        "\n",
        "normalized_features = ['collection_21_days', 'company_size', 'max_team_size', 'min_team_size','mrr',\n",
        "                       \"numuser\", \"numisadmin\",  \"numenabled\", \"numpending\",\"numcountry\", \"numcountry\", \n",
        "                     \"numregion\",\"numrcity\",  \"numphoto\", \"nummos\", \"nummobile\", \"nummobile2\",  \"numchrome\", 'time_diff'\n",
        "                      ]\n",
        "\n",
        "binary_features = ['paying', 'has_logo']\n",
        "\n",
        "untouched_features = ['account_id']\n",
        "\n",
        "target = ['lead_score']\n",
        "\n",
        "# And create a column transformer to handle the manipulation for us\n",
        "preprocess = make_column_transformer(\n",
        "    (OneHotEncoder(), categorical_features),\n",
        "    (Normalizer(), normalized_features),\n",
        "    (Binarizer(), binary_features)\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qhva5OoD_Bu3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "d66b86a2-d70f-4ab0-a754-4836dfd4c811"
      },
      "source": [
        "accounts.describe()\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>account_id</th>\n",
              "      <th>churn_reason</th>\n",
              "      <th>collection_21_days</th>\n",
              "      <th>company_size</th>\n",
              "      <th>has_logo</th>\n",
              "      <th>lead_score</th>\n",
              "      <th>max_team_size</th>\n",
              "      <th>min_team_size</th>\n",
              "      <th>mrr</th>\n",
              "      <th>paying</th>\n",
              "      <th>plan_id</th>\n",
              "      <th>time_diff</th>\n",
              "      <th>numuser</th>\n",
              "      <th>numisadmin</th>\n",
              "      <th>numenabled</th>\n",
              "      <th>numpending</th>\n",
              "      <th>numcountry</th>\n",
              "      <th>numregion</th>\n",
              "      <th>numrcity</th>\n",
              "      <th>numphoto</th>\n",
              "      <th>nummos</th>\n",
              "      <th>nummobile</th>\n",
              "      <th>nummobile2</th>\n",
              "      <th>numchrome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.433661e+06</td>\n",
              "      <td>25256.000000</td>\n",
              "      <td>1.433661e+06</td>\n",
              "      <td>2.984880e+05</td>\n",
              "      <td>1433661.0</td>\n",
              "      <td>1.361978e+06</td>\n",
              "      <td>1.278324e+06</td>\n",
              "      <td>1.278324e+06</td>\n",
              "      <td>48000.000000</td>\n",
              "      <td>1.433661e+06</td>\n",
              "      <td>30089.000000</td>\n",
              "      <td>1.191655e+06</td>\n",
              "      <td>1.432202e+06</td>\n",
              "      <td>1.432202e+06</td>\n",
              "      <td>1.432202e+06</td>\n",
              "      <td>1.432202e+06</td>\n",
              "      <td>1.432202e+06</td>\n",
              "      <td>1.432202e+06</td>\n",
              "      <td>1.432202e+06</td>\n",
              "      <td>1.432202e+06</td>\n",
              "      <td>1.432202e+06</td>\n",
              "      <td>1.432202e+06</td>\n",
              "      <td>455338.000000</td>\n",
              "      <td>917330.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>7.168299e+05</td>\n",
              "      <td>14.748495</td>\n",
              "      <td>7.696428e+00</td>\n",
              "      <td>1.099229e+04</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.489468e-02</td>\n",
              "      <td>1.759639e+01</td>\n",
              "      <td>1.093182e+01</td>\n",
              "      <td>38.804604</td>\n",
              "      <td>2.098753e-02</td>\n",
              "      <td>441.728140</td>\n",
              "      <td>-1.436862e+00</td>\n",
              "      <td>1.584149e+00</td>\n",
              "      <td>1.099776e+00</td>\n",
              "      <td>1.349755e+00</td>\n",
              "      <td>2.830474e-01</td>\n",
              "      <td>1.330080e+00</td>\n",
              "      <td>1.261502e+00</td>\n",
              "      <td>1.251658e+00</td>\n",
              "      <td>1.584149e+00</td>\n",
              "      <td>1.350243e+00</td>\n",
              "      <td>1.350336e+00</td>\n",
              "      <td>1.124859</td>\n",
              "      <td>1.311597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>4.138617e+05</td>\n",
              "      <td>3.266979</td>\n",
              "      <td>1.020891e+02</td>\n",
              "      <td>5.959159e+04</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.558042e-01</td>\n",
              "      <td>6.853256e+01</td>\n",
              "      <td>5.327824e+01</td>\n",
              "      <td>68.695328</td>\n",
              "      <td>1.433425e-01</td>\n",
              "      <td>412.173722</td>\n",
              "      <td>4.720317e+00</td>\n",
              "      <td>3.040914e+00</td>\n",
              "      <td>5.841095e-01</td>\n",
              "      <td>2.042651e+00</td>\n",
              "      <td>1.991992e+00</td>\n",
              "      <td>1.955949e+00</td>\n",
              "      <td>1.895092e+00</td>\n",
              "      <td>1.891116e+00</td>\n",
              "      <td>3.040914e+00</td>\n",
              "      <td>1.963898e+00</td>\n",
              "      <td>1.963990e+00</td>\n",
              "      <td>0.694487</td>\n",
              "      <td>1.664263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-1.440000e+03</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>-1.200000e+01</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3.584160e+05</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>3.000000e+01</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>-5.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>7.168300e+05</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2.100000e+02</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>5.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>232.000000</td>\n",
              "      <td>-3.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.075244e+06</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2.750000e+03</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e+01</td>\n",
              "      <td>6.000000e+00</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>816.000000</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.433659e+06</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>2.080800e+04</td>\n",
              "      <td>2.300000e+06</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>5.000000e+02</td>\n",
              "      <td>5.000000e+02</td>\n",
              "      <td>3468.000000</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1678.000000</td>\n",
              "      <td>1.400000e+01</td>\n",
              "      <td>2.400000e+02</td>\n",
              "      <td>5.700000e+01</td>\n",
              "      <td>2.250000e+02</td>\n",
              "      <td>1.960000e+02</td>\n",
              "      <td>2.180000e+02</td>\n",
              "      <td>2.170000e+02</td>\n",
              "      <td>2.170000e+02</td>\n",
              "      <td>2.400000e+02</td>\n",
              "      <td>2.200000e+02</td>\n",
              "      <td>2.200000e+02</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>189.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         account_id  churn_reason  ...     nummobile2      numchrome\n",
              "count  1.433661e+06  25256.000000  ...  455338.000000  917330.000000\n",
              "mean   7.168299e+05     14.748495  ...       1.124859       1.311597\n",
              "std    4.138617e+05      3.266979  ...       0.694487       1.664263\n",
              "min    1.000000e+00      1.000000  ...       1.000000       1.000000\n",
              "25%    3.584160e+05     13.000000  ...       1.000000       1.000000\n",
              "50%    7.168300e+05     15.000000  ...       1.000000       1.000000\n",
              "75%    1.075244e+06     18.000000  ...       1.000000       1.000000\n",
              "max    1.433659e+06     18.000000  ...      62.000000     189.000000\n",
              "\n",
              "[8 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMEWXPofVXQp",
        "colab_type": "text"
      },
      "source": [
        "###Re-splitting\n",
        "We now need to split our data back to the original train set and test set.\n",
        "\n",
        "We also make sure we keep only the columns we want in the data frame (the features)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2u-ghg6VsuF",
        "colab_type": "code",
        "outputId": "5118dd4a-6825-4419-b8eb-04b273786b35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "# Getting only the relevant features from the dataset\n",
        "dataset = all_features[categorical_features + normalized_features + binary_features + untouched_features + target]\n",
        "\n",
        "# Filling empty values with default values \n",
        "dataset.loc[:,categorical_features] = dataset[categorical_features].fillna('')\n",
        "dataset.loc[:,normalized_features +\n",
        "              binary_features +\n",
        "              untouched_features] = dataset[normalized_features +\n",
        "                                            binary_features +\n",
        "                                            untouched_features].fillna(0)\n",
        "\n",
        "# Splitting them back up to the original train/test split\n",
        "dataset_train = dataset[dataset.reset_index().account_id.isin(train_accounts.account_id)]\n",
        "dataset_test = dataset[dataset.reset_index().account_id.isin(test_accounts.account_id)]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3F7pS0pT7Wb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting them back up to the original train/test split\n",
        "dataset_train = dataset.loc[~(dataset['lead_score'].isna())].reset_index().drop(['index'],axis=1)\n",
        "dataset_test = dataset.loc[(dataset['lead_score'].isna())].reset_index().drop(['index'],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IM1ooT2BQtTE",
        "colab_type": "code",
        "outputId": "abaea956-81d3-4102-a1d6-c0d1947a2fb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset_test[dataset_test['lead_score'].isna()].shape,dataset[dataset['lead_score'].isna()].shape"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((71683, 33), (71683, 33))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeYB9q5Hmdtl",
        "colab_type": "text"
      },
      "source": [
        "###Setting everything up\n",
        "Our dataset is large (1,500,000+ accounts, each has a few users, each has events for every day)\n",
        "\n",
        "We need to work on a smaller batch of the training data so we can iterate more quickly.\n",
        "\n",
        "Once we find a good architecture we can increase the sample size to increase the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kt2uv6bbVVom",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sampled_dataset_train = dataset_train.iloc[sample_without_replacement(dataset_train.shape[0], samples_num)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35doXb6oE99b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "2cd4252a-f059-4b55-ebb9-2e3ef9ed95a6"
      },
      "source": [
        "# We map our features into different types\n",
        "categorical_features = ['country', 'device', 'industry','os' ]\n",
        "#, 'payment_currency','plan_id', 'region','user_goal',\n",
        "  #                     'utm_cluster_id','team_size'\n",
        "\n",
        "normalized_features = ['collection_21_days', 'company_size', 'max_team_size', 'min_team_size','mrr',\n",
        "                       \"numuser\", \"numisadmin\",  \"numenabled\", \"numpending\",\"numcountry\", \"numcountry\", \n",
        "                     \"numregion\",\"numrcity\",  \"numphoto\", \"nummos\", \"nummobile\", \"nummobile2\",  \"numchrome\", 'time_diff'\n",
        "                      ]\n",
        "\n",
        "binary_features = ['paying', 'has_logo']\n",
        "\n",
        "untouched_features = ['account_id']\n",
        "\n",
        "target = ['lead_score']\n",
        "\n",
        "# And create a column transformer to handle the manipulation for us\n",
        "preprocess = make_column_transformer(\n",
        "    (OneHotEncoder(), categorical_features),\n",
        "    (Normalizer(), normalized_features),\n",
        "    (Binarizer(), binary_features)\n",
        ")\n",
        "# Getting only the relevant features from the dataset\n",
        "dataset = all_features[categorical_features + normalized_features + binary_features + untouched_features + target]\n",
        "\n",
        "# Filling empty values with default values \n",
        "dataset.loc[:,categorical_features] = dataset[categorical_features].fillna('')\n",
        "dataset.loc[:,normalized_features +\n",
        "              binary_features +\n",
        "              untouched_features] = dataset[normalized_features +\n",
        "                                            binary_features +\n",
        "                                            untouched_features].fillna(0)\n",
        "\n",
        "# Splitting them back up to the original train/test split\n",
        "dataset_train = dataset[dataset.reset_index().account_id.isin(train_accounts.account_id)]\n",
        "dataset_test = dataset[dataset.reset_index().account_id.isin(test_accounts.account_id)]\n",
        "# Splitting them back up to the original train/test split\n",
        "dataset_train = dataset.loc[~(dataset['lead_score'].isna())].reset_index().drop(['index'],axis=1)\n",
        "dataset_test = dataset.loc[(dataset['lead_score'].isna())].reset_index().drop(['index'],axis=1)\n",
        "sampled_dataset_train = dataset_train.iloc[sample_without_replacement(dataset_train.shape[0], samples_num)]\n",
        "# We fit our column transformer on both the train and the test sets\n",
        "preprocess.fit(sampled_dataset_train.append(dataset_test))\n",
        "\n",
        "# We use transform to finally manipulate the features of our training set\n",
        "X = preprocess.transform(sampled_dataset_train)\n",
        "\n",
        "# Seperating the label\n",
        "y = sampled_dataset_train.pop('lead_score')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oOxDhLgM8a4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# You now need to split the data into YOUR OWN training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=42)\n",
        "\n",
        "# For standardization purposes we store y_test in a y_true variable\n",
        "y_true = y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h49yMjV2HMow",
        "colab_type": "code",
        "outputId": "b6e227e3-283b-4b90-e0a9-7b2b9ae3a3cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        }
      },
      "source": [
        "## (when using google colab)\n",
        "! pip install catboost\n",
        "! pip install plotly_express"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.6/dist-packages (0.16.5)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: pandas>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from catboost) (0.24.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.1.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.16.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.12.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.0.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.1->catboost) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.1->catboost) (2.5.3)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (41.2.0)\n",
            "Requirement already satisfied: plotly_express in /usr/local/lib/python3.6/dist-packages (0.4.1)\n",
            "Requirement already satisfied: plotly>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from plotly_express) (4.1.1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from plotly_express) (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from plotly_express) (1.16.4)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.6/dist-packages (from plotly_express) (0.5.1)\n",
            "Requirement already satisfied: scipy>=0.18 in /usr/local/lib/python3.6/dist-packages (from plotly_express) (1.3.1)\n",
            "Requirement already satisfied: pandas>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from plotly_express) (0.24.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from plotly>=4.1.0->plotly_express) (1.12.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly>=4.1.0->plotly_express) (1.3.3)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.20.0->plotly_express) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.20.0->plotly_express) (2018.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khj17scYHQnH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## General\n",
        "import os \n",
        "import joblib\n",
        "import requests\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "\n",
        "## Data manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "## Modeling\n",
        "### Modeling pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        " \n",
        "### Models\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier    \n",
        "from catboost import CatBoostClassifier, Pool\n",
        "\n",
        "## Visuatlization\n",
        "import plotly \n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lU_fiOvFHE0p",
        "colab_type": "code",
        "outputId": "9cd0ee85-f5e8-4cae-9e64-7d3789741029",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "parameters = {'n_estimators': [50], #[50,100,200]\n",
        "             'max_depth': [5], #[5,10,15],\n",
        "             'criterion': ['gini', 'entropy'],\n",
        "             'max_features': [10]} #[int(np.log2(X_train.shape[1])), int(np.sqrt(X_train.shape[1]))]\n",
        "\n",
        "rf_cv = GridSearchCV(RandomForestClassifier(class_weight='balanced'), \n",
        "                   parameters, \n",
        "                   n_jobs = -1,\n",
        "                   cv = 5,\n",
        "                   refit = True,\n",
        "                   scoring = 'f1')\n",
        "\n",
        "rf_cv.fit(X_train, y_train)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
              "             estimator=RandomForestClassifier(bootstrap=True,\n",
              "                                              class_weight='balanced',\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features='auto',\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              n_estimators='warn', n_jobs=None,\n",
              "                                              oob_score=False,\n",
              "                                              random_state=None, verbose=0,\n",
              "                                              warm_start=False),\n",
              "             iid='warn', n_jobs=-1,\n",
              "             param_grid={'criterion': ['gini', 'entropy'], 'max_depth': [5],\n",
              "                         'max_features': [10], 'n_estimators': [50]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='f1', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQDz6eEvcGLJ",
        "colab_type": "code",
        "outputId": "525069cf-6373-46f0-bd15-bcc903dc9c34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "rf_best_model = rf_cv.best_estimator_\n",
        "rf_best_model"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
              "                       criterion='gini', max_depth=5, max_features=10,\n",
              "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
              "                       min_impurity_split=None, min_samples_leaf=1,\n",
              "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
              "                       n_estimators=50, n_jobs=None, oob_score=False,\n",
              "                       random_state=None, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QW73bMecL9F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_pred = rf_best_model.predict(X_train) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nReMIThzcPnk",
        "colab_type": "code",
        "outputId": "42a850e9-3d06-4708-ed0c-ee98b6b972f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "accuracy_score(y_train_pred, y_train),f1_score(y_train, y_train_pred),precision_score(y_train, y_train_pred),recall_score(y_train, y_train_pred)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8566354489164086,\n",
              " 0.24919032196608878,\n",
              " 0.14323726088678673,\n",
              " 0.9573315061666874)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFMf9ez3cgo8",
        "colab_type": "code",
        "outputId": "8c3f0b84-e2ec-4163-d4ba-d6f163003f57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "confusion_matrix(y_train_pred, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[152491,   1575],\n",
              "       [ 51337,   3597]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeEMwslgdJGF",
        "colab_type": "text"
      },
      "source": [
        "## XGBOOST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-8dISHGdaan",
        "colab_type": "code",
        "outputId": "4b2835e1-c93e-47b1-cf31-23e8936c47da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        }
      },
      "source": [
        "\n",
        "parameters = {\n",
        "    \"gamma\": [0.2, 0.5],\n",
        "    \"learning_rate\": [0.1]\n",
        "}\n",
        "\n",
        "xgb_cv = GridSearchCV(XGBClassifier(class_weight='balanced'), \n",
        "                       parameters, \n",
        "                       n_jobs = -1,\n",
        "                       cv = 5,\n",
        "                       refit = True,\n",
        "                       scoring = 'f1')\n",
        "\n",
        "xgb_cv.fit(X_train, y_train)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning:\n",
            "\n",
            "A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
              "             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
              "                                     class_weight='balanced',\n",
              "                                     colsample_bylevel=1, colsample_bynode=1,\n",
              "                                     colsample_bytree=1, gamma=0,\n",
              "                                     learning_rate=0.1, max_delta_step=0,\n",
              "                                     max_depth=3, min_child_weight=1,\n",
              "                                     missing=None, n_estimators=100, n_jobs=1,\n",
              "                                     nthread=None, objective='binary:logistic',\n",
              "                                     random_state=0, reg_alpha=0, reg_lambda=1,\n",
              "                                     scale_pos_weight=1, seed=None, silent=None,\n",
              "                                     subsample=1, verbosity=1),\n",
              "             iid='warn', n_jobs=-1,\n",
              "             param_grid={'gamma': [0.2, 0.5], 'learning_rate': [0.1]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='f1', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAf6E5EPdeSd",
        "colab_type": "code",
        "outputId": "6621d44a-3d76-445d-b6f7-246c9afbe2a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "xgb_best_model = xgb_cv.best_estimator_\n",
        "xgb_best_model"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', class_weight='balanced',\n",
              "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
              "              gamma=0.5, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NxU4CAwdiES",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_pred = xgb_best_model.predict(X_train) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9C0eQoiqNgrU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "16d39108-6d31-437b-9d2c-2f8ce84a8f72"
      },
      "source": [
        "accuracy_score(y_train_pred, y_train),f1_score(y_train, y_train_pred),precision_score(y_train, y_train_pred),recall_score(y_train, y_train_pred)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9765046439628483,\n",
              " 0.16328555678059536,\n",
              " 0.7099712368168744,\n",
              " 0.09225115236078237)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbxKBGRSeFV_",
        "colab_type": "text"
      },
      "source": [
        "## Catboost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYC1FLLWeVsE",
        "colab_type": "code",
        "outputId": "883c7ae9-df2a-4a99-a15a-08f32b9f8f5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 958
        }
      },
      "source": [
        "parameters = {\n",
        "    \"reg_lambda\": [0, 0.2, 0.5],\n",
        "    \"learning_rate\": [0.1],\n",
        "    \"loss_function\": ['Logloss'] #F1, recall, ... \n",
        "}\n",
        "\n",
        "cat_cv = GridSearchCV(CatBoostClassifier(class_weights = [0.98, 0.02]), \n",
        "                       parameters, \n",
        "                       n_jobs = -1,\n",
        "                       cv = 5,\n",
        "                       refit = True,\n",
        "                       scoring = 'f1',\n",
        "                       verbose = 0)\n",
        "\n",
        "cat_cv.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "CatBoostError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\", line 567, in __call__\n    return self.func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 225, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\", line 516, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.6/dist-packages/catboost/core.py\", line 3463, in fit\n    silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\n  File \"/usr/local/lib/python3.6/dist-packages/catboost/core.py\", line 1388, in _fit\n    save_snapshot, snapshot_file, snapshot_interval, init_model\n  File \"/usr/local/lib/python3.6/dist-packages/catboost/core.py\", line 1283, in _prepare_train_params\n    train_pool = _build_train_pool(X, y, cat_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, column_description)\n  File \"/usr/local/lib/python3.6/dist-packages/catboost/core.py\", line 699, in _build_train_pool\n    group_weight=group_weight, subgroup_id=subgroup_id, pairs_weight=pairs_weight, baseline=baseline)\n  File \"/usr/local/lib/python3.6/dist-packages/catboost/core.py\", line 301, in __init__\n    self._check_data_type(data, cat_features)\n  File \"/usr/local/lib/python3.6/dist-packages/catboost/core.py\", line 395, in _check_data_type\n    raise CatBoostError(\"Invalid data type={}: data must be list(), np.ndarray(), DataFrame(), Series(), FeaturesData or filename str().\".format(type(data)))\n_catboost.CatBoostError: Invalid data type=<class 'scipy.sparse.csr.csr_matrix'>: data must be list(), np.ndarray(), DataFrame(), Series(), FeaturesData or filename str().\n\"\"\"",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-142-0764961f3244>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m                        verbose = 0)\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mcat_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    686\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    665\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 667\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCatBoostError\u001b[0m: Invalid data type=<class 'scipy.sparse.csr.csr_matrix'>: data must be list(), np.ndarray(), DataFrame(), Series(), FeaturesData or filename str()."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJs7Ngnao4nC",
        "colab_type": "text"
      },
      "source": [
        "###Running the model\n",
        "It's the money time, we can finally run our model!\n",
        "\n",
        "First we need to created it, and train(fit) it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-H91z01wwlI",
        "colab_type": "code",
        "outputId": "65e38d75-41d6-4563-85aa-22176c007001",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Now we need to get the predictions of our test set\n",
        "%time y_pred = rf_best_model.predict(X_test)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 310 ms, sys: 3.03 ms, total: 313 ms\n",
            "Wall time: 314 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HNTLiSgpn1W",
        "colab_type": "text"
      },
      "source": [
        "###Model evaluation\n",
        "Now that we have our model and it can predict the lead score based on features, we need a way to test if it's any good"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wglP_6UqOq_",
        "colab_type": "text"
      },
      "source": [
        "####Classification report\n",
        "We use classification_report to get different metrics comparing our prediction to the ground truth."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpmyj4P-flpW",
        "colab_type": "code",
        "outputId": "a5d56cee-c9ca-4340-f768-02c118c3b13a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "print(classification_report(y_true, y_pred, target_names=['Not Lead', 'Lead']))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Not Lead       1.00      0.85      0.92     66270\n",
            "        Lead       0.15      0.96      0.25      1730\n",
            "\n",
            "    accuracy                           0.86     68000\n",
            "   macro avg       0.57      0.91      0.59     68000\n",
            "weighted avg       0.98      0.86      0.90     68000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGt_gAIt5iqF",
        "colab_type": "text"
      },
      "source": [
        "We can also get the MCC score of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_Ax24kc5dgq",
        "colab_type": "code",
        "outputId": "adf96913-1d87-4ce4-ed45-715c15c24ea6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "print('Acc:  {}'.format(metrics.accuracy_score(y_true, y_pred)))\n",
        "print('MCC: {}'.format(metrics.matthews_corrcoef(y_true, y_pred)))\n",
        "print('F1:  {}'.format(metrics.f1_score(y_true, y_pred)))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acc:  0.8565147058823529\n",
            "MCC: 0.34327628356588114\n",
            "F1:  0.25376673040152964\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0CC280TpnGV",
        "colab_type": "text"
      },
      "source": [
        "####Plotting the confusion matrix\n",
        "Confusion matrices are useful for comparing our predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRd1YjZFy-UJ",
        "colab_type": "code",
        "outputId": "de417dc9-f554-44e3-805c-804e078a6918",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "fig, axs = plt.subplots(ncols=2, figsize=(14,4))\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "ticks = ['Not Lead', 'Lead']\n",
        "cmap = sns.color_palette(\"Blues\")\n",
        "\n",
        "# We normalize our data to see more accurate comparsion\n",
        "sns.heatmap(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], annot=True, ax=axs[0], cmap=cmap)\n",
        "axs[0].set(title=\"Normalized confusion matrix\", xlabel=\"Prediction\", ylabel=\"Truth\", xticklabels=ticks, yticklabels=ticks)\n",
        "\n",
        "# We also plot the original numbers to get the whole picture\n",
        "sns.heatmap(cm, annot=True, ax=axs[1], fmt='g', cmap=cmap)\n",
        "axs[1].set(title=\"Confusion matrix\", xlabel=\"Prediction\", ylabel=\"Truth\", xticklabels=ticks, yticklabels=ticks);"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzYAAAEWCAYAAAC0fAJeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1008x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FUIBac_ZRLp",
        "colab_type": "text"
      },
      "source": [
        "###Submitting results\n",
        "After you ran several iterations, and you think your model is good enough, you can send it to us and we'll add your score on the leaderboard!\n",
        "\n",
        "You have to get the results into the following format:\n",
        "```python\n",
        "{\"9023749\": 1, \"9837598\": 0, ...}\n",
        "```\n",
        "\n",
        "This is a dictionary where the keys are `account_id`s and the values are the predicted lead_score.\n",
        "\n",
        "_Make sure you send us **all** the test accounts!_\n",
        "\n",
        "_There should be exactly `71,683` of them!_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmB5Vx91ao4t",
        "colab_type": "text"
      },
      "source": [
        "####Prediction\n",
        "First of all, just like before, we have to predict the lead_score.\n",
        "\n",
        "This time you need to use the test set _we_ provided."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xv469ucaoJ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_test = dataset[dataset['lead_score'].isna()]\n",
        "submission_account_ids = dataset_test.account_id\n",
        "\n",
        "X_submission = preprocess.transform(dataset_test)\n",
        "\n",
        "y_pred_submission = rf_best_model.predict(X_submission)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQnIWRVbcltE",
        "colab_type": "text"
      },
      "source": [
        "####Submission\n",
        "Now that we have our submission predictions, we need to pack them up into a compatible format for our server to handle.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFfuM8ve8t1w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a dictionary where the keys are the account_ids\n",
        "# and the values are your predictions\n",
        "prediction = dict(zip(map(str, map(int,submission_account_ids)), map(int,y_pred_submission)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltQWs9SEP89a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "32628a2b-2780-45ee-f7a3-a2958bf6a73d"
      },
      "source": [
        "prediction\n"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'7': 1,\n",
              " '44': 0,\n",
              " '45': 0,\n",
              " '46': 0,\n",
              " '53': 0,\n",
              " '56': 0,\n",
              " '62': 0,\n",
              " '70': 0,\n",
              " '157': 0,\n",
              " '166': 0,\n",
              " '187': 0,\n",
              " '223': 0,\n",
              " '237': 0,\n",
              " '241': 0,\n",
              " '250': 0,\n",
              " '253': 0,\n",
              " '270': 0,\n",
              " '284': 0,\n",
              " '291': 1,\n",
              " '296': 0,\n",
              " '298': 0,\n",
              " '320': 0,\n",
              " '347': 0,\n",
              " '375': 0,\n",
              " '390': 0,\n",
              " '396': 1,\n",
              " '414': 0,\n",
              " '432': 0,\n",
              " '442': 0,\n",
              " '494': 0,\n",
              " '533': 0,\n",
              " '584': 0,\n",
              " '604': 1,\n",
              " '609': 0,\n",
              " '610': 0,\n",
              " '616': 1,\n",
              " '677': 0,\n",
              " '688': 0,\n",
              " '733': 0,\n",
              " '750': 0,\n",
              " '757': 0,\n",
              " '796': 0,\n",
              " '802': 0,\n",
              " '805': 1,\n",
              " '868': 0,\n",
              " '879': 0,\n",
              " '906': 0,\n",
              " '921': 0,\n",
              " '937': 1,\n",
              " '956': 0,\n",
              " '975': 0,\n",
              " '1008': 0,\n",
              " '1016': 0,\n",
              " '1038': 0,\n",
              " '1065': 0,\n",
              " '1068': 0,\n",
              " '1088': 0,\n",
              " '1147': 0,\n",
              " '1163': 0,\n",
              " '1169': 0,\n",
              " '1171': 0,\n",
              " '1177': 0,\n",
              " '1201': 0,\n",
              " '1202': 0,\n",
              " '1213': 0,\n",
              " '1246': 0,\n",
              " '1256': 0,\n",
              " '1257': 0,\n",
              " '1272': 0,\n",
              " '1284': 0,\n",
              " '1306': 0,\n",
              " '1313': 0,\n",
              " '1317': 0,\n",
              " '1328': 0,\n",
              " '1338': 0,\n",
              " '1353': 0,\n",
              " '1372': 0,\n",
              " '1461': 0,\n",
              " '1469': 0,\n",
              " '1471': 0,\n",
              " '1473': 1,\n",
              " '1486': 0,\n",
              " '1512': 0,\n",
              " '1533': 0,\n",
              " '1540': 0,\n",
              " '1553': 0,\n",
              " '1568': 1,\n",
              " '1576': 0,\n",
              " '1577': 1,\n",
              " '1583': 0,\n",
              " '1595': 0,\n",
              " '1597': 0,\n",
              " '1620': 0,\n",
              " '1632': 0,\n",
              " '1648': 0,\n",
              " '1668': 0,\n",
              " '1686': 0,\n",
              " '1697': 1,\n",
              " '1700': 0,\n",
              " '1756': 0,\n",
              " '1767': 0,\n",
              " '1770': 0,\n",
              " '1842': 0,\n",
              " '1870': 0,\n",
              " '1877': 0,\n",
              " '1895': 0,\n",
              " '1922': 0,\n",
              " '1958': 0,\n",
              " '1962': 0,\n",
              " '1972': 0,\n",
              " '1974': 0,\n",
              " '1978': 0,\n",
              " '1986': 0,\n",
              " '1991': 0,\n",
              " '1994': 0,\n",
              " '2045': 0,\n",
              " '2053': 0,\n",
              " '2063': 0,\n",
              " '2068': 0,\n",
              " '2069': 0,\n",
              " '2081': 0,\n",
              " '2084': 1,\n",
              " '2120': 0,\n",
              " '2140': 0,\n",
              " '2148': 0,\n",
              " '2161': 0,\n",
              " '2162': 0,\n",
              " '2183': 0,\n",
              " '2196': 0,\n",
              " '2219': 0,\n",
              " '2222': 0,\n",
              " '2227': 0,\n",
              " '2228': 0,\n",
              " '2229': 0,\n",
              " '2270': 1,\n",
              " '2284': 0,\n",
              " '2296': 1,\n",
              " '2299': 0,\n",
              " '2347': 0,\n",
              " '2359': 0,\n",
              " '2372': 0,\n",
              " '2373': 0,\n",
              " '2389': 0,\n",
              " '2397': 0,\n",
              " '2412': 0,\n",
              " '2414': 1,\n",
              " '2415': 0,\n",
              " '2438': 0,\n",
              " '2461': 1,\n",
              " '2470': 0,\n",
              " '2480': 1,\n",
              " '2494': 0,\n",
              " '2502': 0,\n",
              " '2532': 1,\n",
              " '2535': 0,\n",
              " '2546': 0,\n",
              " '2579': 0,\n",
              " '2588': 0,\n",
              " '2606': 0,\n",
              " '2608': 0,\n",
              " '2636': 0,\n",
              " '2649': 1,\n",
              " '2720': 0,\n",
              " '2739': 0,\n",
              " '2776': 0,\n",
              " '2792': 1,\n",
              " '2816': 0,\n",
              " '2820': 0,\n",
              " '2855': 0,\n",
              " '2874': 0,\n",
              " '2875': 0,\n",
              " '2877': 0,\n",
              " '2908': 1,\n",
              " '2932': 0,\n",
              " '2933': 0,\n",
              " '2944': 0,\n",
              " '2960': 0,\n",
              " '2966': 0,\n",
              " '2976': 0,\n",
              " '2983': 0,\n",
              " '2993': 0,\n",
              " '3016': 1,\n",
              " '3043': 0,\n",
              " '3048': 1,\n",
              " '3107': 1,\n",
              " '3108': 1,\n",
              " '3121': 0,\n",
              " '3141': 0,\n",
              " '3157': 0,\n",
              " '3158': 0,\n",
              " '3172': 0,\n",
              " '3191': 0,\n",
              " '3195': 1,\n",
              " '3214': 0,\n",
              " '3215': 0,\n",
              " '3226': 0,\n",
              " '3232': 1,\n",
              " '3274': 0,\n",
              " '3281': 0,\n",
              " '3285': 1,\n",
              " '3287': 1,\n",
              " '3301': 0,\n",
              " '3309': 0,\n",
              " '3321': 0,\n",
              " '3336': 0,\n",
              " '3370': 0,\n",
              " '3372': 0,\n",
              " '3405': 0,\n",
              " '3412': 0,\n",
              " '3441': 0,\n",
              " '3445': 0,\n",
              " '3519': 0,\n",
              " '3530': 0,\n",
              " '3547': 0,\n",
              " '3553': 0,\n",
              " '3569': 0,\n",
              " '3580': 0,\n",
              " '3583': 0,\n",
              " '3598': 0,\n",
              " '3601': 0,\n",
              " '3628': 0,\n",
              " '3630': 1,\n",
              " '3650': 0,\n",
              " '3654': 0,\n",
              " '3665': 0,\n",
              " '3674': 0,\n",
              " '3675': 0,\n",
              " '3694': 0,\n",
              " '3701': 1,\n",
              " '3704': 0,\n",
              " '3750': 1,\n",
              " '3821': 0,\n",
              " '3898': 0,\n",
              " '3931': 0,\n",
              " '3951': 0,\n",
              " '3986': 1,\n",
              " '4012': 0,\n",
              " '4026': 0,\n",
              " '4028': 0,\n",
              " '4048': 0,\n",
              " '4055': 0,\n",
              " '4134': 0,\n",
              " '4204': 0,\n",
              " '4209': 0,\n",
              " '4218': 0,\n",
              " '4251': 0,\n",
              " '4273': 1,\n",
              " '4351': 0,\n",
              " '4364': 0,\n",
              " '4371': 0,\n",
              " '4378': 0,\n",
              " '4392': 0,\n",
              " '4399': 0,\n",
              " '4402': 0,\n",
              " '4417': 0,\n",
              " '4449': 0,\n",
              " '4466': 0,\n",
              " '4504': 0,\n",
              " '4523': 0,\n",
              " '4545': 0,\n",
              " '4550': 0,\n",
              " '4601': 0,\n",
              " '4608': 0,\n",
              " '4637': 0,\n",
              " '4695': 0,\n",
              " '4699': 0,\n",
              " '4700': 0,\n",
              " '4725': 0,\n",
              " '4745': 0,\n",
              " '4759': 0,\n",
              " '4760': 1,\n",
              " '4766': 0,\n",
              " '4782': 0,\n",
              " '4794': 1,\n",
              " '4795': 1,\n",
              " '4831': 0,\n",
              " '4832': 0,\n",
              " '4885': 0,\n",
              " '4920': 0,\n",
              " '4954': 0,\n",
              " '4961': 0,\n",
              " '4966': 0,\n",
              " '4975': 0,\n",
              " '5001': 0,\n",
              " '5046': 0,\n",
              " '5050': 0,\n",
              " '5067': 0,\n",
              " '5086': 0,\n",
              " '5125': 0,\n",
              " '5140': 1,\n",
              " '5143': 0,\n",
              " '5159': 0,\n",
              " '5184': 0,\n",
              " '5186': 0,\n",
              " '5193': 0,\n",
              " '5218': 0,\n",
              " '5254': 1,\n",
              " '5279': 0,\n",
              " '5286': 0,\n",
              " '5295': 0,\n",
              " '5313': 0,\n",
              " '5329': 0,\n",
              " '5331': 0,\n",
              " '5339': 0,\n",
              " '5377': 0,\n",
              " '5381': 0,\n",
              " '5423': 0,\n",
              " '5441': 0,\n",
              " '5470': 0,\n",
              " '5482': 1,\n",
              " '5488': 0,\n",
              " '5500': 0,\n",
              " '5530': 0,\n",
              " '5540': 0,\n",
              " '5542': 0,\n",
              " '5591': 0,\n",
              " '5634': 0,\n",
              " '5656': 0,\n",
              " '5674': 0,\n",
              " '5684': 0,\n",
              " '5686': 0,\n",
              " '5768': 0,\n",
              " '5771': 0,\n",
              " '5773': 0,\n",
              " '5778': 0,\n",
              " '5800': 0,\n",
              " '5832': 1,\n",
              " '5839': 0,\n",
              " '5860': 0,\n",
              " '5862': 0,\n",
              " '5939': 0,\n",
              " '5950': 0,\n",
              " '5987': 0,\n",
              " '6017': 0,\n",
              " '6058': 0,\n",
              " '6087': 0,\n",
              " '6132': 0,\n",
              " '6153': 0,\n",
              " '6168': 0,\n",
              " '6176': 0,\n",
              " '6204': 0,\n",
              " '6209': 0,\n",
              " '6211': 1,\n",
              " '6235': 0,\n",
              " '6246': 0,\n",
              " '6248': 0,\n",
              " '6259': 0,\n",
              " '6262': 0,\n",
              " '6273': 1,\n",
              " '6274': 0,\n",
              " '6281': 0,\n",
              " '6321': 0,\n",
              " '6323': 0,\n",
              " '6376': 0,\n",
              " '6394': 0,\n",
              " '6431': 0,\n",
              " '6439': 0,\n",
              " '6463': 0,\n",
              " '6483': 0,\n",
              " '6507': 0,\n",
              " '6517': 0,\n",
              " '6523': 1,\n",
              " '6525': 0,\n",
              " '6530': 0,\n",
              " '6577': 1,\n",
              " '6587': 0,\n",
              " '6594': 1,\n",
              " '6604': 0,\n",
              " '6607': 0,\n",
              " '6641': 0,\n",
              " '6650': 0,\n",
              " '6666': 0,\n",
              " '6685': 0,\n",
              " '6690': 1,\n",
              " '6706': 0,\n",
              " '6715': 0,\n",
              " '6725': 1,\n",
              " '6767': 0,\n",
              " '6775': 0,\n",
              " '6781': 0,\n",
              " '6788': 0,\n",
              " '6813': 0,\n",
              " '6867': 0,\n",
              " '6873': 0,\n",
              " '6922': 0,\n",
              " '6940': 0,\n",
              " '6945': 0,\n",
              " '6950': 0,\n",
              " '6962': 0,\n",
              " '6979': 0,\n",
              " '6996': 0,\n",
              " '7022': 0,\n",
              " '7028': 0,\n",
              " '7082': 0,\n",
              " '7099': 0,\n",
              " '7102': 0,\n",
              " '7105': 0,\n",
              " '7122': 0,\n",
              " '7165': 1,\n",
              " '7181': 1,\n",
              " '7213': 1,\n",
              " '7215': 0,\n",
              " '7220': 0,\n",
              " '7231': 0,\n",
              " '7245': 1,\n",
              " '7260': 1,\n",
              " '7318': 0,\n",
              " '7319': 0,\n",
              " '7323': 0,\n",
              " '7328': 0,\n",
              " '7352': 0,\n",
              " '7357': 0,\n",
              " '7358': 0,\n",
              " '7369': 0,\n",
              " '7375': 0,\n",
              " '7391': 1,\n",
              " '7411': 0,\n",
              " '7445': 0,\n",
              " '7450': 0,\n",
              " '7461': 0,\n",
              " '7474': 1,\n",
              " '7514': 0,\n",
              " '7554': 0,\n",
              " '7565': 1,\n",
              " '7618': 0,\n",
              " '7625': 0,\n",
              " '7641': 0,\n",
              " '7687': 0,\n",
              " '7697': 0,\n",
              " '7725': 0,\n",
              " '7743': 0,\n",
              " '7829': 1,\n",
              " '7832': 0,\n",
              " '7852': 0,\n",
              " '7861': 0,\n",
              " '7892': 0,\n",
              " '7893': 1,\n",
              " '7906': 0,\n",
              " '7908': 0,\n",
              " '7947': 0,\n",
              " '7976': 0,\n",
              " '7977': 1,\n",
              " '8007': 0,\n",
              " '8019': 1,\n",
              " '8065': 0,\n",
              " '8111': 0,\n",
              " '8115': 0,\n",
              " '8141': 0,\n",
              " '8148': 0,\n",
              " '8175': 0,\n",
              " '8232': 0,\n",
              " '8254': 0,\n",
              " '8259': 0,\n",
              " '8290': 0,\n",
              " '8299': 0,\n",
              " '8320': 0,\n",
              " '8347': 0,\n",
              " '8367': 1,\n",
              " '8387': 1,\n",
              " '8401': 0,\n",
              " '8412': 0,\n",
              " '8436': 0,\n",
              " '8438': 0,\n",
              " '8471': 0,\n",
              " '8488': 0,\n",
              " '8501': 0,\n",
              " '8504': 0,\n",
              " '8511': 0,\n",
              " '8530': 0,\n",
              " '8594': 0,\n",
              " '8627': 0,\n",
              " '8640': 1,\n",
              " '8666': 0,\n",
              " '8671': 0,\n",
              " '8687': 0,\n",
              " '8690': 1,\n",
              " '8723': 0,\n",
              " '8728': 0,\n",
              " '8803': 0,\n",
              " '8824': 0,\n",
              " '8858': 0,\n",
              " '8865': 0,\n",
              " '8873': 0,\n",
              " '8892': 0,\n",
              " '8958': 0,\n",
              " '8970': 0,\n",
              " '8978': 0,\n",
              " '8979': 0,\n",
              " '8992': 0,\n",
              " '9025': 0,\n",
              " '9049': 0,\n",
              " '9059': 0,\n",
              " '9064': 0,\n",
              " '9082': 0,\n",
              " '9139': 0,\n",
              " '9147': 0,\n",
              " '9246': 0,\n",
              " '9288': 0,\n",
              " '9298': 0,\n",
              " '9362': 1,\n",
              " '9413': 1,\n",
              " '9485': 0,\n",
              " '9492': 0,\n",
              " '9541': 0,\n",
              " '9543': 0,\n",
              " '9556': 0,\n",
              " '9581': 0,\n",
              " '9646': 0,\n",
              " '9647': 0,\n",
              " '9666': 1,\n",
              " '9672': 0,\n",
              " '9694': 0,\n",
              " '9706': 1,\n",
              " '9738': 0,\n",
              " '9741': 1,\n",
              " '9780': 0,\n",
              " '9811': 0,\n",
              " '9862': 0,\n",
              " '9881': 0,\n",
              " '9888': 0,\n",
              " '9907': 0,\n",
              " '9909': 0,\n",
              " '9916': 0,\n",
              " '9922': 0,\n",
              " '9932': 1,\n",
              " '9953': 0,\n",
              " '9956': 0,\n",
              " '9993': 0,\n",
              " '10008': 1,\n",
              " '10013': 0,\n",
              " '10074': 0,\n",
              " '10104': 0,\n",
              " '10111': 0,\n",
              " '10127': 0,\n",
              " '10154': 0,\n",
              " '10156': 0,\n",
              " '10175': 0,\n",
              " '10209': 1,\n",
              " '10228': 0,\n",
              " '10271': 0,\n",
              " '10304': 0,\n",
              " '10404': 0,\n",
              " '10443': 0,\n",
              " '10485': 0,\n",
              " '10490': 0,\n",
              " '10498': 1,\n",
              " '10546': 1,\n",
              " '10561': 0,\n",
              " '10576': 0,\n",
              " '10612': 0,\n",
              " '10634': 0,\n",
              " '10642': 0,\n",
              " '10657': 0,\n",
              " '10684': 0,\n",
              " '10728': 0,\n",
              " '10736': 0,\n",
              " '10787': 1,\n",
              " '10839': 0,\n",
              " '10848': 0,\n",
              " '10849': 0,\n",
              " '10850': 0,\n",
              " '10864': 0,\n",
              " '10865': 0,\n",
              " '10894': 0,\n",
              " '10904': 0,\n",
              " '10918': 0,\n",
              " '10934': 0,\n",
              " '10940': 0,\n",
              " '10951': 0,\n",
              " '11005': 0,\n",
              " '11016': 0,\n",
              " '11036': 0,\n",
              " '11060': 0,\n",
              " '11094': 0,\n",
              " '11105': 0,\n",
              " '11116': 0,\n",
              " '11132': 0,\n",
              " '11140': 0,\n",
              " '11141': 0,\n",
              " '11172': 0,\n",
              " '11232': 0,\n",
              " '11252': 0,\n",
              " '11261': 0,\n",
              " '11272': 0,\n",
              " '11282': 1,\n",
              " '11304': 0,\n",
              " '11346': 0,\n",
              " '11348': 0,\n",
              " '11367': 0,\n",
              " '11404': 1,\n",
              " '11413': 1,\n",
              " '11454': 0,\n",
              " '11455': 0,\n",
              " '11465': 0,\n",
              " '11481': 0,\n",
              " '11490': 0,\n",
              " '11526': 0,\n",
              " '11562': 0,\n",
              " '11581': 0,\n",
              " '11591': 0,\n",
              " '11598': 0,\n",
              " '11624': 0,\n",
              " '11640': 0,\n",
              " '11659': 0,\n",
              " '11840': 1,\n",
              " '11841': 0,\n",
              " '11850': 0,\n",
              " '11853': 0,\n",
              " '11859': 0,\n",
              " '11896': 0,\n",
              " '11912': 0,\n",
              " '11917': 0,\n",
              " '11945': 0,\n",
              " '11953': 0,\n",
              " '11984': 0,\n",
              " '11989': 0,\n",
              " '11999': 0,\n",
              " '12038': 0,\n",
              " '12064': 0,\n",
              " '12112': 0,\n",
              " '12144': 0,\n",
              " '12159': 0,\n",
              " '12228': 0,\n",
              " '12244': 0,\n",
              " '12270': 0,\n",
              " '12294': 0,\n",
              " '12309': 0,\n",
              " '12329': 0,\n",
              " '12422': 1,\n",
              " '12460': 0,\n",
              " '12472': 1,\n",
              " '12485': 0,\n",
              " '12489': 0,\n",
              " '12499': 0,\n",
              " '12504': 1,\n",
              " '12512': 0,\n",
              " '12524': 1,\n",
              " '12525': 1,\n",
              " '12545': 0,\n",
              " '12556': 0,\n",
              " '12568': 1,\n",
              " '12572': 0,\n",
              " '12576': 1,\n",
              " '12615': 0,\n",
              " '12618': 0,\n",
              " '12631': 0,\n",
              " '12688': 0,\n",
              " '12738': 0,\n",
              " '12781': 0,\n",
              " '12782': 0,\n",
              " '12801': 0,\n",
              " '12858': 1,\n",
              " '12859': 0,\n",
              " '12888': 1,\n",
              " '12892': 1,\n",
              " '12992': 0,\n",
              " '13013': 0,\n",
              " '13062': 0,\n",
              " '13068': 0,\n",
              " '13079': 1,\n",
              " '13093': 0,\n",
              " '13105': 0,\n",
              " '13108': 0,\n",
              " '13128': 0,\n",
              " '13129': 0,\n",
              " '13253': 0,\n",
              " '13272': 0,\n",
              " '13275': 0,\n",
              " '13277': 0,\n",
              " '13283': 1,\n",
              " '13286': 0,\n",
              " '13303': 1,\n",
              " '13326': 0,\n",
              " '13332': 0,\n",
              " '13339': 0,\n",
              " '13346': 0,\n",
              " '13353': 1,\n",
              " '13387': 0,\n",
              " '13404': 0,\n",
              " '13451': 0,\n",
              " '13456': 1,\n",
              " '13496': 1,\n",
              " '13498': 0,\n",
              " '13512': 0,\n",
              " '13547': 0,\n",
              " '13565': 0,\n",
              " '13574': 0,\n",
              " '13592': 0,\n",
              " '13597': 0,\n",
              " '13695': 0,\n",
              " '13707': 0,\n",
              " '13723': 0,\n",
              " '13730': 0,\n",
              " '13741': 0,\n",
              " '13742': 0,\n",
              " '13758': 1,\n",
              " '13762': 0,\n",
              " '13844': 0,\n",
              " '13845': 0,\n",
              " '13848': 1,\n",
              " '13858': 0,\n",
              " '13865': 1,\n",
              " '13883': 0,\n",
              " '13892': 0,\n",
              " '13898': 0,\n",
              " '13904': 0,\n",
              " '13915': 0,\n",
              " '13943': 0,\n",
              " '13944': 0,\n",
              " '13970': 0,\n",
              " '13991': 0,\n",
              " '14005': 1,\n",
              " '14051': 0,\n",
              " '14076': 0,\n",
              " '14090': 0,\n",
              " '14092': 1,\n",
              " '14104': 0,\n",
              " '14144': 1,\n",
              " '14163': 1,\n",
              " '14167': 0,\n",
              " '14191': 1,\n",
              " '14253': 0,\n",
              " '14275': 0,\n",
              " '14298': 0,\n",
              " '14322': 0,\n",
              " '14323': 0,\n",
              " '14337': 0,\n",
              " '14341': 0,\n",
              " '14379': 0,\n",
              " '14454': 0,\n",
              " '14471': 0,\n",
              " '14489': 0,\n",
              " '14494': 0,\n",
              " '14510': 0,\n",
              " '14522': 0,\n",
              " '14541': 0,\n",
              " '14543': 0,\n",
              " '14567': 0,\n",
              " '14574': 0,\n",
              " '14580': 0,\n",
              " '14584': 1,\n",
              " '14597': 0,\n",
              " '14601': 0,\n",
              " '14632': 1,\n",
              " '14662': 0,\n",
              " '14668': 0,\n",
              " '14680': 0,\n",
              " '14690': 0,\n",
              " '14694': 1,\n",
              " '14729': 0,\n",
              " '14747': 0,\n",
              " '14754': 0,\n",
              " '14763': 0,\n",
              " '14825': 0,\n",
              " '14894': 0,\n",
              " '14902': 1,\n",
              " '14944': 0,\n",
              " '14946': 0,\n",
              " '14981': 0,\n",
              " '15006': 0,\n",
              " '15013': 0,\n",
              " '15054': 0,\n",
              " '15057': 1,\n",
              " '15073': 0,\n",
              " '15093': 0,\n",
              " '15115': 0,\n",
              " '15147': 0,\n",
              " '15154': 0,\n",
              " '15166': 0,\n",
              " '15171': 0,\n",
              " '15178': 0,\n",
              " '15218': 0,\n",
              " '15238': 0,\n",
              " '15282': 1,\n",
              " '15283': 0,\n",
              " '15360': 0,\n",
              " '15390': 1,\n",
              " '15395': 0,\n",
              " '15428': 0,\n",
              " '15434': 0,\n",
              " '15453': 0,\n",
              " '15469': 1,\n",
              " '15482': 1,\n",
              " '15491': 0,\n",
              " '15511': 0,\n",
              " '15512': 0,\n",
              " '15554': 0,\n",
              " '15560': 0,\n",
              " '15585': 1,\n",
              " '15592': 0,\n",
              " '15598': 0,\n",
              " '15606': 0,\n",
              " '15618': 0,\n",
              " '15638': 0,\n",
              " '15652': 0,\n",
              " '15694': 0,\n",
              " '15706': 0,\n",
              " '15718': 1,\n",
              " '15720': 0,\n",
              " '15723': 0,\n",
              " '15729': 0,\n",
              " '15758': 1,\n",
              " '15763': 1,\n",
              " '15780': 0,\n",
              " '15789': 0,\n",
              " '15802': 0,\n",
              " '15823': 0,\n",
              " '15848': 0,\n",
              " '15884': 0,\n",
              " '15908': 0,\n",
              " '15925': 0,\n",
              " '15945': 1,\n",
              " '15957': 0,\n",
              " '15964': 1,\n",
              " '15965': 0,\n",
              " '16026': 0,\n",
              " '16040': 1,\n",
              " '16092': 0,\n",
              " '16095': 1,\n",
              " '16119': 0,\n",
              " '16139': 0,\n",
              " '16141': 1,\n",
              " '16144': 0,\n",
              " '16151': 0,\n",
              " '16183': 0,\n",
              " '16200': 0,\n",
              " '16211': 0,\n",
              " '16216': 0,\n",
              " '16273': 0,\n",
              " '16305': 0,\n",
              " '16331': 0,\n",
              " '16337': 0,\n",
              " '16379': 0,\n",
              " '16443': 0,\n",
              " '16465': 0,\n",
              " '16470': 0,\n",
              " '16484': 0,\n",
              " '16489': 0,\n",
              " '16519': 0,\n",
              " '16565': 0,\n",
              " '16578': 1,\n",
              " '16590': 0,\n",
              " '16625': 0,\n",
              " '16708': 0,\n",
              " '16717': 0,\n",
              " '16718': 0,\n",
              " '16751': 0,\n",
              " '16783': 0,\n",
              " '16792': 0,\n",
              " '16805': 0,\n",
              " '16825': 0,\n",
              " '16867': 0,\n",
              " '16885': 1,\n",
              " '16946': 0,\n",
              " '16947': 0,\n",
              " '16948': 0,\n",
              " '16952': 1,\n",
              " '16957': 0,\n",
              " '16961': 0,\n",
              " '16972': 1,\n",
              " '16983': 1,\n",
              " '17002': 0,\n",
              " '17024': 0,\n",
              " '17032': 0,\n",
              " '17142': 0,\n",
              " '17169': 0,\n",
              " '17182': 0,\n",
              " '17225': 0,\n",
              " '17245': 0,\n",
              " '17271': 0,\n",
              " '17281': 0,\n",
              " '17287': 0,\n",
              " '17302': 0,\n",
              " '17344': 0,\n",
              " '17376': 0,\n",
              " '17385': 0,\n",
              " '17408': 0,\n",
              " '17422': 0,\n",
              " '17424': 0,\n",
              " '17449': 1,\n",
              " '17456': 0,\n",
              " '17459': 0,\n",
              " '17462': 0,\n",
              " '17478': 1,\n",
              " '17482': 0,\n",
              " '17514': 0,\n",
              " '17527': 0,\n",
              " '17562': 1,\n",
              " '17592': 0,\n",
              " '17596': 0,\n",
              " '17598': 0,\n",
              " '17617': 0,\n",
              " '17659': 0,\n",
              " '17709': 0,\n",
              " '17712': 0,\n",
              " '17742': 1,\n",
              " '17759': 0,\n",
              " '17796': 0,\n",
              " '17812': 0,\n",
              " '17827': 0,\n",
              " '17828': 0,\n",
              " '17838': 0,\n",
              " '17874': 0,\n",
              " '17889': 0,\n",
              " '17901': 0,\n",
              " '17932': 0,\n",
              " '17937': 0,\n",
              " '17952': 0,\n",
              " '17958': 0,\n",
              " '17962': 0,\n",
              " '17984': 0,\n",
              " '17987': 1,\n",
              " '18014': 1,\n",
              " '18034': 0,\n",
              " '18036': 0,\n",
              " '18044': 0,\n",
              " '18048': 0,\n",
              " '18051': 0,\n",
              " '18052': 0,\n",
              " '18065': 0,\n",
              " '18084': 1,\n",
              " '18110': 0,\n",
              " '18121': 0,\n",
              " '18123': 0,\n",
              " '18156': 0,\n",
              " '18160': 0,\n",
              " '18176': 0,\n",
              " '18180': 0,\n",
              " '18198': 0,\n",
              " '18206': 0,\n",
              " '18207': 0,\n",
              " '18220': 0,\n",
              " '18228': 0,\n",
              " '18249': 1,\n",
              " '18275': 1,\n",
              " '18277': 0,\n",
              " '18314': 0,\n",
              " '18317': 0,\n",
              " '18357': 0,\n",
              " '18362': 0,\n",
              " '18378': 0,\n",
              " '18383': 0,\n",
              " '18389': 0,\n",
              " '18473': 0,\n",
              " '18512': 1,\n",
              " '18533': 0,\n",
              " '18592': 0,\n",
              " '18634': 0,\n",
              " '18671': 0,\n",
              " '18686': 0,\n",
              " '18688': 0,\n",
              " '18712': 0,\n",
              " '18713': 0,\n",
              " '18722': 1,\n",
              " '18783': 0,\n",
              " '18795': 0,\n",
              " '18805': 0,\n",
              " '18808': 0,\n",
              " '18823': 0,\n",
              " '18826': 0,\n",
              " '18846': 0,\n",
              " '18862': 0,\n",
              " '18864': 0,\n",
              " '18924': 0,\n",
              " '18927': 0,\n",
              " '18932': 0,\n",
              " '18934': 0,\n",
              " '18973': 0,\n",
              " '19042': 0,\n",
              " '19127': 0,\n",
              " '19129': 0,\n",
              " '19135': 0,\n",
              " '19172': 1,\n",
              " '19219': 0,\n",
              " '19232': 0,\n",
              " '19317': 0,\n",
              " '19319': 0,\n",
              " '19346': 0,\n",
              " '19366': 1,\n",
              " '19418': 1,\n",
              " '19444': 0,\n",
              " '19448': 1,\n",
              " '19457': 0,\n",
              " '19469': 0,\n",
              " '19477': 0,\n",
              " '19486': 0,\n",
              " '19489': 0,\n",
              " '19515': 0,\n",
              " '19529': 0,\n",
              " '19536': 0,\n",
              " '19544': 0,\n",
              " '19551': 0,\n",
              " '19566': 0,\n",
              " '19575': 0,\n",
              " '19591': 0,\n",
              " '19613': 0,\n",
              " '19628': 0,\n",
              " '19668': 0,\n",
              " '19670': 0,\n",
              " '19686': 0,\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdlT5SRJdadv",
        "colab_type": "text"
      },
      "source": [
        "We now just send the results to our server and wait for the score!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1Ev6lafdZoJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d77427d6-c35f-4398-9ebe-b7b6d6a6bd71"
      },
      "source": [
        "# Importing stuff for http requests\n",
        "from urllib import request\n",
        "import json\n",
        "\n",
        "# We validate first that we actually send all the test accounts expected to be sent\n",
        "if y_pred_submission.shape[0] != 71683 or submission_account_ids.shape[0] != 71683:\n",
        "  raise Exception(\"You have to send all of the accounts! Expected: (71683, 71683), Got: ({}, {})\".format(y_pred_submission.shape[0], submission_account_ids.shape[0]))\n",
        "\n",
        "if \"group_name\" not in vars() or group_name == \"\":\n",
        "  group_name = input(\"Please enter your group's name:\")\n",
        "\n",
        "data = json.dumps({'submitter': group_name, 'predictions': prediction}).encode('utf-8')\n",
        "\n",
        "req = request.Request(f\"https://leaderboard.datahack.org.il/monday/api/\",\n",
        "                      headers={'Content-Type': 'application/json'},\n",
        "                      data=data)\n",
        "\n",
        "res = request.urlopen(req)\n",
        "print(json.load(res))"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'member': 'Lamassim', 'rank': 1, 'score': 0.3406032668717866}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}