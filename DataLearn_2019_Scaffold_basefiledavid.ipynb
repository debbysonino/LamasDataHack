{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataLearn 2019 - Scaffold.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/debbysonino/LamasDataHack/blob/master/DataLearn_2019_Scaffold_basefiledavid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTnHVMK-wyjz",
        "colab_type": "text"
      },
      "source": [
        "&nbsp; ![alt text](https://s3.amazonaws.com/monday.com/static/svg/monday-logos/monday-footer-logo.svg)\n",
        "\n",
        "#Model scaffold\n",
        "This notebook is intended to get you up and running faster.\n",
        "\n",
        "It has the basic scaffold of an ML model, including:\n",
        "* Data loading\n",
        "* Feature extraction\n",
        "* Columns transformation\n",
        "* Training\n",
        "* Evaluating\n",
        "* Submitting results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhDZdkDTjyf-",
        "colab_type": "text"
      },
      "source": [
        "###Getting our depnedncies (and data!)\n",
        "First we'll import our relevant libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gao6_ydqMgBS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# General DS libraries we are going to need\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import timedelta\n",
        "\n",
        "# Importing our base model\n",
        "# [REDACTED ML MODEL USED]\n",
        "\n",
        "# Imports for working with our large dataset\n",
        "from sklearn.utils.random import sample_without_replacement\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# We need those for data manipulation and getting our features ready for the model\n",
        "from sklearn.preprocessing import OneHotEncoder, Normalizer, Binarizer\n",
        "from sklearn.compose import make_column_transformer\n",
        "\n",
        "# These can be used to measure our model's performance\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Ignore DataFrame assignment warnings\n",
        "pd.options.mode.chained_assignment = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jNoDkmNAsCaY"
      },
      "source": [
        "\n",
        "We set a few constants to use later on for sampeling and running the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JhqmBDsksCaa",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Model parameters { run: \"auto\" }\n",
        "# n_neighbors = 7 #@param {type:\"slider\", min:1, max:30, step:1}\n",
        "group_name = \"Lamassim\" #@param {type:\"string\"}\n",
        "samples_num = 1360000 #@param {type:\"slider\", min:0, max:1500000, step:10000}\n",
        "n_jobs = -1 #@param {type:\"slider\", min:-1, max:32, step:1}\n",
        "path_prefix = \"https://storage.googleapis.com/mondaycom-datahack/final_sets\" #@param [\"https://storage.googleapis.com/mondaycom-datahack/final_sets\", \"https://mondaycom-datahack.s3.amazonaws.com/final_sets\"] {allow-input: true}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DpkqHB9lsUmQ"
      },
      "source": [
        "Next we'll load all the different parts of our dataset\n",
        "\n",
        "<br/>\n",
        "\n",
        "_Our use my data loading [snippet](https://colab.research.google.com/drive/1_Y-sZ5eHIDlDUMuLCwfnbuJdLh0DTXmO#scrollTo=5HGlaJTEAYJu&line=23&uniqifier=1)!_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2x0lOgBZRP_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# We define the datasets we want to load\n",
        "datasets = ('accounts', 'users', 'events', 'subscriptions')\n",
        "source_prefix = 'https://storage.googleapis.com/mondaycom-datahack/final_sets/'\n",
        "\n",
        "local_dir = './datasets/datahack/'\n",
        "file_prefix = 'train_'\n",
        "file_suffix = ''\n",
        "file_extension = 'csv'\n",
        "\n",
        "# We create a directory for the datasets if it doesn't exist\n",
        "if not os.path.exists(local_dir):\n",
        "    os.makedirs(local_dir)\n",
        "\n",
        "# For each dataset we want, we check if we already downloaded it and fix it if we didn't\n",
        "for dataset in datasets:\n",
        "  if not os.path.isfile('{}{}{}{}.{}'.format(local_dir, file_prefix, dataset, file_suffix, file_extension)):\n",
        "    !curl {source_prefix}{file_prefix}{dataset}{file_suffix}.{file_extension} --output {local_dir}{file_prefix}{dataset}{file_suffix}.{file_extension}\n",
        "\n",
        "  # Load the datasets into a DataFrame using pandas\n",
        "  globals()['{}{}'.format(file_prefix, dataset)] = pd.read_csv('{}{}{}{}.{}'.format(local_dir, file_prefix, dataset, file_suffix, file_extension), low_memory=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdEFqnpfKjmk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# We define the datasets we want to load\n",
        "datasets = ('accounts', 'users', 'events', 'subscriptions')\n",
        "source_prefix = 'https://storage.googleapis.com/mondaycom-datahack/final_sets/'\n",
        "\n",
        "local_dir = './datasets/datahack/'\n",
        "file_prefix = 'test_'\n",
        "file_suffix = ''\n",
        "file_extension = 'csv'\n",
        "\n",
        "# We create a directory for the datasets if it doesn't exist\n",
        "if not os.path.exists(local_dir):\n",
        "    os.makedirs(local_dir)\n",
        "\n",
        "# For each dataset we want, we check if we already downloaded it and fix it if we didn't\n",
        "for dataset in datasets:\n",
        "  if not os.path.isfile('{}{}{}{}.{}'.format(local_dir, file_prefix, dataset, file_suffix, file_extension)):\n",
        "    !curl {source_prefix}{file_prefix}{dataset}{file_suffix}.{file_extension} --output {local_dir}{file_prefix}{dataset}{file_suffix}.{file_extension}\n",
        "\n",
        "  # Load the datasets into a DataFrame using pandas\n",
        "  globals()['{}{}'.format(file_prefix, dataset)] = pd.read_csv('{}{}{}{}.{}'.format(local_dir, file_prefix, dataset, file_suffix, file_extension), low_memory=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yh1wGtOsUcnf",
        "colab_type": "text"
      },
      "source": [
        "We need to add our test sets to our train sets and work on both at the same time.\n",
        "\n",
        "We'll split them back up before training and inference."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNcD_YSBUbiY",
        "colab_type": "code",
        "outputId": "3acf207e-10a3-4b39-ba5c-ba0d52f4002a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "accounts = train_accounts.append(test_accounts)\n",
        "users = train_users.append(test_users)\n",
        "events = train_events.append(test_events)\n",
        "subscriptions = train_subscriptions.append(test_subscriptions)"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:6692: FutureWarning:\n",
            "\n",
            "Sorting because non-concatenation axis is not aligned. A future version\n",
            "of pandas will change to not sort by default.\n",
            "\n",
            "To accept the future behavior, pass 'sort=False'.\n",
            "\n",
            "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jo5vLhgAlY-K",
        "colab_type": "text"
      },
      "source": [
        "###Feature engineering\n",
        "In this block we add a new feature of `[REDACTED]` extracted from the user `[REDACTED]`\n",
        "\n",
        "We also seperate all the `[REDACTED]` users into a different DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6VUhsrzlvES",
        "colab_type": "text"
      },
      "source": [
        "Let's enrich our data a bit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f9X2owrCpl0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accounts[\"numuser\"]=users.groupby(\"account_id\").user_id.size()\n",
        "accounts[\"numisadmin\"]=users.groupby(\"account_id\").is_admin.sum()\n",
        "accounts[\"numenabled\"]=users.groupby(\"account_id\").enabled.sum()\n",
        "accounts[\"numpending\"]=users.groupby(\"account_id\").pending.sum()\n",
        "accounts[\"numcountry\"]=users.groupby(\"account_id\").country.count()\n",
        "accounts[\"numregion\"]=users.groupby(\"account_id\").region.count()\n",
        "accounts[\"numrcity\"]=users.groupby(\"account_id\").city.count()\n",
        "accounts[\"numphoto\"]=users.groupby(\"account_id\").has_photo.sum()\n",
        "accounts[\"nummos\"]=users.groupby(\"account_id\").os.count()\n",
        "accounts[\"nummobile\"]=users.groupby(\"account_id\").device.count()\n",
        "accounts[\"nummobile2\"]=users[users[\"device\"]==\"mobile\"].groupby(\"account_id\").device.count()\n",
        "accounts[\"numchrome\"]=users[users[\"browser\"]==\"chrome\"].groupby(\"account_id\").browser.count()\n",
        "#accounts[\"vetekuser\"]=users.groupby(\"account_id\").created_at.min()\n",
        "#accounts[\"vetekactive\"]=users.groupby(\"account_id\").became_active_at.min()\n",
        "\n",
        "\n",
        "#accounts[\"vetekuser\"]=users.groupby(\"account_id\").created_at.min()\n",
        "#accounts[\"vetekactive\"]=users.groupby(\"account_id\").became_active_at.min()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28hS7VxA6utB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sub_df = pd.read_csv('https://storage.googleapis.com/mondaycom-datahack/final_sets/train_subscriptions.csv', nrows=7000000000)\n",
        "def upgrade(row):\n",
        "  return abs(row[\"plan_id\"]-row[\"prev_plan_id\"])>0\n",
        "\n",
        "\n",
        "subscriptions[\"plan_upgrade\"] =  subscriptions.apply(upgrade ,axis=1)\n",
        "\n",
        "subscriptions['status_success']=subscriptions['status'].fillna('SUCCESS')\n",
        "subscriptions['status_success']=subscriptions['status_success']=='SUCCESS'\n",
        "#sub_df[sub_df['status_success']==0].sum() # check if mrr=0 for status=failed\n",
        "\n",
        "account_subs=subscriptions.groupby('account_id').agg({\"subscription_id\":\"count\",\"plan_id\":\"nunique\", \"plan_upgrade\": \"mean\",\"mrr_gain\":\"sum\"})\n",
        "account_subs.rename(columns={'subscription_id':'sub_count',\n",
        "                          'plan_id':'unique_plan',\n",
        "                          \n",
        "                             'mrr_gain':'mrr_gain_sum'}, \n",
        "                 inplace=True)\n",
        "accounts=pd.merge(accounts, account_subs, on='account_id', how='left')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dx8Xl1jjrrrW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#events_by_account_user = events.groupby(['account_id'])['payment_events'].sum()\n",
        "accounts['browser'] = accounts['browser'].fillna('chrome')\n",
        "accounts['churn_reason'] = accounts['churn_reason'].fillna(0)\n",
        "accounts['payment_events_by_account']=events.groupby(['account_id'])['payment_events'].sum()\n",
        "accounts['payment_events_by_account'] = accounts['payment_events_by_account'].fillna(0)\n",
        "accounts['last_event_day']=events.groupby(['account_id'])['date'].max()\n",
        "# accounts['last_event_day'].fillna(accounts['subscription_started_at'])\n",
        "# from the resume data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZt4tF3xyjSg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "accounts['Avg_event_by_total']=(events.groupby(['account_id']).total_events.sum()/events.groupby(['account_id']).date.count())\n",
        "accounts['Avg_event_by_column']=(events.groupby(['account_id']).column_events.sum()/events.groupby(['account_id']).date.count())\n",
        "accounts['Avg_event_by_board']=(events.groupby(['account_id']).board_events.sum()/events.groupby(['account_id']).date.count())\n",
        "accounts['Avg_event_by_num']=(events.groupby(['account_id']).num_of_boards.sum()/events.groupby(['account_id']).date.count())\n",
        "accounts['Avg_event_by_count']=(events.groupby(['account_id']).count_kind_columns.sum()/events.groupby(['account_id']).date.count())\n",
        "accounts['Avg_event_by_content']=(events.groupby(['account_id']).content_events.sum()/events.groupby(['account_id']).date.count())\n",
        "accounts['Avg_event_by_group']=(events.groupby(['account_id']).group_events.sum()/events.groupby(['account_id']).date.count())\n",
        "accounts['Avg_event_by_invite']=(events.groupby(['account_id']).invite_events.sum()/events.groupby(['account_id']).date.count())\n",
        "accounts['Avg_event_by_import']=(events.groupby(['account_id']).import_events.sum()/events.groupby(['account_id']).date.count())\n",
        "accounts['Avg_event_by_notification']=(events.groupby(['account_id']).notification_events.sum()/events.groupby(['account_id']).date.count())\n",
        "accounts['Avg_event_by_new']=(events.groupby(['account_id']).new_entry_events.sum()/events.groupby(['account_id']).date.count())\n",
        "accounts['Avg_event_by_payment']=(events.groupby(['account_id']).payment_events.sum()/events.groupby(['account_id']).date.count())\n",
        "accounts['Avg_event_by_inbox']=(events.groupby(['account_id']).inbox_events.sum()/events.groupby(['account_id']).date.count())\n",
        "accounts['Avg_event_by_communicating']=(events.groupby(['account_id']).communicating_events.sum()/events.groupby(['account_id']).date.count())\n",
        "accounts['Avg_event_by_non']=(events.groupby(['account_id']).non_communicating_events.sum()/events.groupby(['account_id']).date.count())\n",
        "accounts['Avg_event_by_web']=(events.groupby(['account_id']).web_events.sum()/events.groupby(['account_id']).date.count())\n",
        "accounts['Avg_event_by_ios']=(events.groupby(['account_id']).ios_events.sum()/events.groupby(['account_id']).date.count())\n",
        "accounts['Avg_event_by_android']=(events.groupby(['account_id']).android_events.sum()/events.groupby(['account_id']).date.count())\n",
        "accounts['Avg_event_by_desktop']=(events.groupby(['account_id']).desktop_app_events.sum()/events.groupby(['account_id']).date.count())\n",
        "accounts['Avg_event_by_empty']=(events.groupby(['account_id']).empty_events.sum()/events.groupby(['account_id']).date.count())\n",
        "\n",
        "\n",
        "accounts['P_event_by_column']=events.groupby(['account_id']).column_events.sum()/(events.groupby(['account_id']).total_events.sum())                                                                   \n",
        "accounts['P_event_by_board']=events.groupby(['account_id'])['board_events'].sum()/(events.groupby(['account_id']).total_events.sum())                                                 \n",
        "accounts['P_event_by_num']=events.groupby(['account_id']).num_of_boards.sum()/(events.groupby(['account_id']).total_events.sum())\n",
        "accounts['P_event_by_count']=events.groupby(['account_id']).count_kind_columns.sum()/(events.groupby(['account_id']).total_events.sum())\n",
        "accounts['P_event_by_content']=events.groupby(['account_id']).content_events.sum()/(events.groupby(['account_id']).total_events.sum())\n",
        "accounts['P_event_by_group']=events.groupby(['account_id']).group_events.sum()/(events.groupby(['account_id']).total_events.sum())\n",
        "accounts['P_event_by_invite']=events.groupby(['account_id']).invite_events.sum()/(events.groupby(['account_id']).total_events.sum())\n",
        "accounts['P_event_by_import']=events.groupby(['account_id']).import_events.sum()/(events.groupby(['account_id']).total_events.sum())                                                                \n",
        "accounts['P_event_by_notification']=events.groupby(['account_id']).notification_events.sum()/(events.groupby(['account_id']).total_events.sum())\n",
        "accounts['P_event_by_new']=events.groupby(['account_id']).new_entry_events.sum()/(events.groupby(['account_id']).total_events.sum())\n",
        "accounts['P_event_by_payment']=events.groupby(['account_id']).payment_events.sum()/(events.groupby(['account_id']).total_events.sum())\n",
        "accounts['P_event_by_inbox']=events.groupby(['account_id']).inbox_events.sum()/(events.groupby(['account_id']).total_events.sum())\n",
        "accounts['P_event_by_communicating']=events.groupby(['account_id']).communicating_events.sum()/(events.groupby(['account_id']).total_events.sum())\n",
        "accounts['P_event_by_non']=events.groupby(['account_id']).non_communicating_events.sum()/(events.groupby(['account_id']).total_events.sum())\n",
        "accounts['P_event_by_web']=events.groupby(['account_id']).web_events.sum()/(events.groupby(['account_id']).total_events.sum())\n",
        "accounts['P_event_by_ios']=events.groupby(['account_id']).ios_events.sum()/(events.groupby(['account_id']).total_events.sum())\n",
        "accounts['P_event_by_android']=events.groupby(['account_id']).android_events.sum()/(events.groupby(['account_id']).total_events.sum())\n",
        "accounts['P_event_by_desktop']=events.groupby(['account_id']).desktop_app_events.sum()/(events.groupby(['account_id']).total_events.sum())\n",
        "accounts['P_event_by_empty']=events.groupby(['account_id']).empty_events.sum()/(events.groupby(['account_id']).total_events.sum())\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-u2yzKUsKqsa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_features=accounts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acqwq8wE16Af",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "b1efed35-99fd-4c3e-e3b1-d041001d2390"
      },
      "source": [
        "all_features.head()"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>account_id</th>\n",
              "      <th>account_name</th>\n",
              "      <th>browser</th>\n",
              "      <th>churn_date</th>\n",
              "      <th>churn_reason</th>\n",
              "      <th>collection_21_days</th>\n",
              "      <th>company_size</th>\n",
              "      <th>country</th>\n",
              "      <th>created_at</th>\n",
              "      <th>device</th>\n",
              "      <th>has_logo</th>\n",
              "      <th>industry</th>\n",
              "      <th>lead_score</th>\n",
              "      <th>max_team_size</th>\n",
              "      <th>min_team_size</th>\n",
              "      <th>mrr</th>\n",
              "      <th>os</th>\n",
              "      <th>paying</th>\n",
              "      <th>payment_currency</th>\n",
              "      <th>plan_id</th>\n",
              "      <th>region</th>\n",
              "      <th>subscription_started_at</th>\n",
              "      <th>team_size</th>\n",
              "      <th>time_diff</th>\n",
              "      <th>trial_start</th>\n",
              "      <th>user_description</th>\n",
              "      <th>user_goal</th>\n",
              "      <th>utm_cluster_id</th>\n",
              "      <th>numuser</th>\n",
              "      <th>numisadmin</th>\n",
              "      <th>numenabled</th>\n",
              "      <th>numpending</th>\n",
              "      <th>numcountry</th>\n",
              "      <th>numregion</th>\n",
              "      <th>numrcity</th>\n",
              "      <th>numphoto</th>\n",
              "      <th>nummos</th>\n",
              "      <th>nummobile</th>\n",
              "      <th>nummobile2</th>\n",
              "      <th>numchrome</th>\n",
              "      <th>...</th>\n",
              "      <th>last_event_day</th>\n",
              "      <th>Avg_event_by_total</th>\n",
              "      <th>Avg_event_by_column</th>\n",
              "      <th>Avg_event_by_board</th>\n",
              "      <th>Avg_event_by_num</th>\n",
              "      <th>Avg_event_by_count</th>\n",
              "      <th>Avg_event_by_content</th>\n",
              "      <th>Avg_event_by_group</th>\n",
              "      <th>Avg_event_by_invite</th>\n",
              "      <th>Avg_event_by_import</th>\n",
              "      <th>Avg_event_by_notification</th>\n",
              "      <th>Avg_event_by_new</th>\n",
              "      <th>Avg_event_by_payment</th>\n",
              "      <th>Avg_event_by_inbox</th>\n",
              "      <th>Avg_event_by_communicating</th>\n",
              "      <th>Avg_event_by_non</th>\n",
              "      <th>Avg_event_by_web</th>\n",
              "      <th>Avg_event_by_ios</th>\n",
              "      <th>Avg_event_by_android</th>\n",
              "      <th>Avg_event_by_desktop</th>\n",
              "      <th>Avg_event_by_empty</th>\n",
              "      <th>P_event_by_column</th>\n",
              "      <th>P_event_by_board</th>\n",
              "      <th>P_event_by_num</th>\n",
              "      <th>P_event_by_count</th>\n",
              "      <th>P_event_by_content</th>\n",
              "      <th>P_event_by_group</th>\n",
              "      <th>P_event_by_invite</th>\n",
              "      <th>P_event_by_import</th>\n",
              "      <th>P_event_by_notification</th>\n",
              "      <th>P_event_by_new</th>\n",
              "      <th>P_event_by_payment</th>\n",
              "      <th>P_event_by_inbox</th>\n",
              "      <th>P_event_by_communicating</th>\n",
              "      <th>P_event_by_non</th>\n",
              "      <th>P_event_by_web</th>\n",
              "      <th>P_event_by_ios</th>\n",
              "      <th>P_event_by_android</th>\n",
              "      <th>P_event_by_desktop</th>\n",
              "      <th>P_event_by_empty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Gardner, Barron and Keller</td>\n",
              "      <td>microsoft edge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>AU</td>\n",
              "      <td>2019-01-01 00:01:15</td>\n",
              "      <td>desktop</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>windows</td>\n",
              "      <td>0</td>\n",
              "      <td>AUD</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New South Wales</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11.0</td>\n",
              "      <td>2019-01-01 00:01:15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>orders</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>Dunn Ltd</td>\n",
              "      <td>chrome</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>US</td>\n",
              "      <td>2019-01-01 00:01:52</td>\n",
              "      <td>mobile</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ios</td>\n",
              "      <td>0</td>\n",
              "      <td>USD</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New Jersey</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2019-01-01 00:01:52</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>2019-01-14</td>\n",
              "      <td>8.833333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>5.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.166667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018868</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.018868</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018868</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.037736</td>\n",
              "      <td>0.622642</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.132075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>Boone Inc</td>\n",
              "      <td>chrome</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>US</td>\n",
              "      <td>2019-01-01 00:03:12</td>\n",
              "      <td>desktop</td>\n",
              "      <td>1</td>\n",
              "      <td>Other</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>windows</td>\n",
              "      <td>0</td>\n",
              "      <td>USD</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Louisiana</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>2019-01-01 00:03:12</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>todos</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>2019-01-14</td>\n",
              "      <td>119.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2.250000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>2.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>94.833333</td>\n",
              "      <td>15.25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004202</td>\n",
              "      <td>0.018908</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004902</td>\n",
              "      <td>0.018908</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.796919</td>\n",
              "      <td>0.128151</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.005602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.0</td>\n",
              "      <td>Christian, Carroll and Davis</td>\n",
              "      <td>chrome</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IL</td>\n",
              "      <td>2019-01-01 00:04:11</td>\n",
              "      <td>mobile</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>android</td>\n",
              "      <td>0</td>\n",
              "      <td>USD</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Tel Aviv</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2019-01-01 00:04:11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2019-01-14</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>8.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.013889</td>\n",
              "      <td>0.013889</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.013889</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.027778</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.013889</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.013889</td>\n",
              "      <td>0.013889</td>\n",
              "      <td>0.069444</td>\n",
              "      <td>0.722222</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.125000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>Brooks-Oliver</td>\n",
              "      <td>chrome</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>US</td>\n",
              "      <td>2019-01-01 00:04:21</td>\n",
              "      <td>desktop</td>\n",
              "      <td>1</td>\n",
              "      <td>Design</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>chrome_os</td>\n",
              "      <td>0</td>\n",
              "      <td>USD</td>\n",
              "      <td>NaN</td>\n",
              "      <td>North Carolina</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>2019-04-04 11:09:12</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>todos</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>2019-01-14</td>\n",
              "      <td>13.857143</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020619</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020619</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.432990</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.072165</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 85 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   account_id  ... P_event_by_empty\n",
              "0         1.0  ...              NaN\n",
              "1         2.0  ...         0.132075\n",
              "2         3.0  ...         0.005602\n",
              "3         4.0  ...         0.125000\n",
              "4         5.0  ...         0.072165\n",
              "\n",
              "[5 rows x 85 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfUboEib17-A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moN6itpxQAGi",
        "colab_type": "code",
        "outputId": "e9c16e3a-f8ad-4740-a335-c50c1b59f7fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "all_features[all_features['lead_score'].isna()].shape[0]"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "71683"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SngUmaPImHZF",
        "colab_type": "text"
      },
      "source": [
        "###Data preperation\n",
        "After we created our raw features we need to make sure the fit the way our ML model expects to receive them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-KJGAevD0iT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We map our features into different types\n",
        "categorical_features = ['country', 'device',  'industry','os', 'payment_currency','plan_id', 'region','user_goal',\n",
        "                       'utm_cluster_id','team_size', 'browser' , 'churn_reason']\n",
        "\n",
        "normalized_features = ['collection_21_days', 'company_size', 'max_team_size', 'min_team_size','mrr',\n",
        "                       \"numuser\", \"numisadmin\",  \"numenabled\", \"numpending\",\"numcountry\", \"numcountry\", \n",
        "                     \"numregion\",\"numrcity\",  \"numphoto\", \"nummos\", \"nummobile\", \"nummobile2\",  \"numchrome\", 'time_diff',\n",
        "                      'plan_upgrade', 'payment_events_by_account'\n",
        "                      ,'Avg_event_by_total', 'Avg_event_by_column','Avg_event_by_board','Avg_event_by_num','Avg_event_by_count',\n",
        "                     'Avg_event_by_content','Avg_event_by_group','Avg_event_by_invite','Avg_event_by_import','Avg_event_by_notification',\n",
        "                      'Avg_event_by_new','Avg_event_by_payment','Avg_event_by_inbox','Avg_event_by_communicating','Avg_event_by_non',\n",
        "                      'Avg_event_by_web','Avg_event_by_ios','Avg_event_by_android','Avg_event_by_desktop','Avg_event_by_empty',\n",
        "                      'P_event_by_column','P_event_by_board','P_event_by_num','P_event_by_count','P_event_by_content','P_event_by_group',\n",
        "                      'P_event_by_invite','P_event_by_import','P_event_by_notification','P_event_by_new','P_event_by_payment',\n",
        "                      'P_event_by_inbox','P_event_by_communicating','P_event_by_non','P_event_by_web','P_event_by_ios','P_event_by_android',\n",
        "                      'P_event_by_desktop','P_event_by_empty', 'sub_count', 'mrr_gain_sum','unique_plan'\n",
        "                      ]\n",
        "\n",
        "binary_features = ['paying', 'has_logo']\n",
        "\n",
        "untouched_features = ['account_id']\n",
        "\n",
        "target = ['lead_score']\n",
        "\n",
        "# And create a column transformer to handle the manipulation for us\n",
        "preprocess = make_column_transformer(\n",
        "    (OneHotEncoder(), categorical_features),\n",
        "    (Normalizer(), normalized_features),\n",
        "    (Binarizer(), binary_features)\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qhva5OoD_Bu3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "5b1c6a51-4129-43e7-8869-008917619ccb"
      },
      "source": [
        "accounts.describe()\n"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>account_id</th>\n",
              "      <th>churn_reason</th>\n",
              "      <th>collection_21_days</th>\n",
              "      <th>company_size</th>\n",
              "      <th>has_logo</th>\n",
              "      <th>lead_score</th>\n",
              "      <th>max_team_size</th>\n",
              "      <th>min_team_size</th>\n",
              "      <th>mrr</th>\n",
              "      <th>paying</th>\n",
              "      <th>plan_id</th>\n",
              "      <th>time_diff</th>\n",
              "      <th>numuser</th>\n",
              "      <th>numisadmin</th>\n",
              "      <th>numenabled</th>\n",
              "      <th>numpending</th>\n",
              "      <th>numcountry</th>\n",
              "      <th>numregion</th>\n",
              "      <th>numrcity</th>\n",
              "      <th>numphoto</th>\n",
              "      <th>nummos</th>\n",
              "      <th>nummobile</th>\n",
              "      <th>nummobile2</th>\n",
              "      <th>numchrome</th>\n",
              "      <th>sub_count</th>\n",
              "      <th>unique_plan</th>\n",
              "      <th>plan_upgrade</th>\n",
              "      <th>mrr_gain_sum</th>\n",
              "      <th>payment_events_by_account</th>\n",
              "      <th>Avg_event_by_total</th>\n",
              "      <th>Avg_event_by_column</th>\n",
              "      <th>Avg_event_by_board</th>\n",
              "      <th>Avg_event_by_num</th>\n",
              "      <th>Avg_event_by_count</th>\n",
              "      <th>Avg_event_by_content</th>\n",
              "      <th>Avg_event_by_group</th>\n",
              "      <th>Avg_event_by_invite</th>\n",
              "      <th>Avg_event_by_import</th>\n",
              "      <th>Avg_event_by_notification</th>\n",
              "      <th>Avg_event_by_new</th>\n",
              "      <th>Avg_event_by_payment</th>\n",
              "      <th>Avg_event_by_inbox</th>\n",
              "      <th>Avg_event_by_communicating</th>\n",
              "      <th>Avg_event_by_non</th>\n",
              "      <th>Avg_event_by_web</th>\n",
              "      <th>Avg_event_by_ios</th>\n",
              "      <th>Avg_event_by_android</th>\n",
              "      <th>Avg_event_by_desktop</th>\n",
              "      <th>Avg_event_by_empty</th>\n",
              "      <th>P_event_by_column</th>\n",
              "      <th>P_event_by_board</th>\n",
              "      <th>P_event_by_num</th>\n",
              "      <th>P_event_by_count</th>\n",
              "      <th>P_event_by_content</th>\n",
              "      <th>P_event_by_group</th>\n",
              "      <th>P_event_by_invite</th>\n",
              "      <th>P_event_by_import</th>\n",
              "      <th>P_event_by_notification</th>\n",
              "      <th>P_event_by_new</th>\n",
              "      <th>P_event_by_payment</th>\n",
              "      <th>P_event_by_inbox</th>\n",
              "      <th>P_event_by_communicating</th>\n",
              "      <th>P_event_by_non</th>\n",
              "      <th>P_event_by_web</th>\n",
              "      <th>P_event_by_ios</th>\n",
              "      <th>P_event_by_android</th>\n",
              "      <th>P_event_by_desktop</th>\n",
              "      <th>P_event_by_empty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.433661e+06</td>\n",
              "      <td>1.433661e+06</td>\n",
              "      <td>1.433661e+06</td>\n",
              "      <td>2.984880e+05</td>\n",
              "      <td>1433661.0</td>\n",
              "      <td>1.361978e+06</td>\n",
              "      <td>1.278324e+06</td>\n",
              "      <td>1.278324e+06</td>\n",
              "      <td>48000.000000</td>\n",
              "      <td>1.433661e+06</td>\n",
              "      <td>30089.000000</td>\n",
              "      <td>1.191655e+06</td>\n",
              "      <td>1.432202e+06</td>\n",
              "      <td>1.432202e+06</td>\n",
              "      <td>1.432202e+06</td>\n",
              "      <td>1.432202e+06</td>\n",
              "      <td>1.432202e+06</td>\n",
              "      <td>1.432202e+06</td>\n",
              "      <td>1.432202e+06</td>\n",
              "      <td>1.432202e+06</td>\n",
              "      <td>1.432202e+06</td>\n",
              "      <td>1.432202e+06</td>\n",
              "      <td>455338.000000</td>\n",
              "      <td>917330.000000</td>\n",
              "      <td>34424.000000</td>\n",
              "      <td>34424.000000</td>\n",
              "      <td>34424.000000</td>\n",
              "      <td>34424.000000</td>\n",
              "      <td>1.433661e+06</td>\n",
              "      <td>1.433219e+06</td>\n",
              "      <td>1.433219e+06</td>\n",
              "      <td>1.433219e+06</td>\n",
              "      <td>1.433219e+06</td>\n",
              "      <td>1.433219e+06</td>\n",
              "      <td>1.433219e+06</td>\n",
              "      <td>1.433219e+06</td>\n",
              "      <td>1.433219e+06</td>\n",
              "      <td>1.433219e+06</td>\n",
              "      <td>1.433219e+06</td>\n",
              "      <td>1.433219e+06</td>\n",
              "      <td>1.433219e+06</td>\n",
              "      <td>1.433219e+06</td>\n",
              "      <td>1.433219e+06</td>\n",
              "      <td>1.433219e+06</td>\n",
              "      <td>1.433219e+06</td>\n",
              "      <td>1.433219e+06</td>\n",
              "      <td>1.433219e+06</td>\n",
              "      <td>1.433219e+06</td>\n",
              "      <td>1.433219e+06</td>\n",
              "      <td>1.433219e+06</td>\n",
              "      <td>1.433219e+06</td>\n",
              "      <td>1.433219e+06</td>\n",
              "      <td>1.433219e+06</td>\n",
              "      <td>1.433219e+06</td>\n",
              "      <td>1.433219e+06</td>\n",
              "      <td>1.433219e+06</td>\n",
              "      <td>1.433219e+06</td>\n",
              "      <td>1.433219e+06</td>\n",
              "      <td>1.433219e+06</td>\n",
              "      <td>1.433219e+06</td>\n",
              "      <td>1.433219e+06</td>\n",
              "      <td>1.433219e+06</td>\n",
              "      <td>1.433219e+06</td>\n",
              "      <td>1.433219e+06</td>\n",
              "      <td>1.433219e+06</td>\n",
              "      <td>1.433219e+06</td>\n",
              "      <td>1.433219e+06</td>\n",
              "      <td>1.433219e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>7.168299e+05</td>\n",
              "      <td>2.598160e-01</td>\n",
              "      <td>7.696428e+00</td>\n",
              "      <td>1.099229e+04</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.489468e-02</td>\n",
              "      <td>1.759639e+01</td>\n",
              "      <td>1.093182e+01</td>\n",
              "      <td>38.804604</td>\n",
              "      <td>2.098753e-02</td>\n",
              "      <td>441.728140</td>\n",
              "      <td>-1.436862e+00</td>\n",
              "      <td>1.584149e+00</td>\n",
              "      <td>1.099776e+00</td>\n",
              "      <td>1.349755e+00</td>\n",
              "      <td>2.830474e-01</td>\n",
              "      <td>1.330080e+00</td>\n",
              "      <td>1.261502e+00</td>\n",
              "      <td>1.251658e+00</td>\n",
              "      <td>1.584149e+00</td>\n",
              "      <td>1.350243e+00</td>\n",
              "      <td>1.350336e+00</td>\n",
              "      <td>1.124859</td>\n",
              "      <td>1.311597</td>\n",
              "      <td>4.012753</td>\n",
              "      <td>1.402423</td>\n",
              "      <td>0.080532</td>\n",
              "      <td>68.849582</td>\n",
              "      <td>7.098554e-01</td>\n",
              "      <td>3.370153e+01</td>\n",
              "      <td>1.217727e+00</td>\n",
              "      <td>1.336154e-01</td>\n",
              "      <td>2.326409e-01</td>\n",
              "      <td>1.621937e-01</td>\n",
              "      <td>6.161036e-01</td>\n",
              "      <td>4.017152e-02</td>\n",
              "      <td>2.280932e-02</td>\n",
              "      <td>1.329239e-01</td>\n",
              "      <td>1.033228e-02</td>\n",
              "      <td>2.314668e-01</td>\n",
              "      <td>5.307396e-02</td>\n",
              "      <td>3.382414e-01</td>\n",
              "      <td>1.581899e-01</td>\n",
              "      <td>3.275373e+00</td>\n",
              "      <td>1.903302e+01</td>\n",
              "      <td>1.621475e+00</td>\n",
              "      <td>5.713963e-01</td>\n",
              "      <td>5.085479e-01</td>\n",
              "      <td>7.548322e+00</td>\n",
              "      <td>1.430344e-02</td>\n",
              "      <td>3.980413e-03</td>\n",
              "      <td>6.273497e-03</td>\n",
              "      <td>2.879296e-03</td>\n",
              "      <td>9.444778e-03</td>\n",
              "      <td>4.950964e-04</td>\n",
              "      <td>9.220303e-04</td>\n",
              "      <td>9.732084e-04</td>\n",
              "      <td>1.007840e-04</td>\n",
              "      <td>7.764763e-03</td>\n",
              "      <td>1.270479e-03</td>\n",
              "      <td>9.948865e-03</td>\n",
              "      <td>4.645309e-03</td>\n",
              "      <td>5.617934e-02</td>\n",
              "      <td>4.155679e-01</td>\n",
              "      <td>4.317006e-02</td>\n",
              "      <td>2.076084e-02</td>\n",
              "      <td>3.610412e-03</td>\n",
              "      <td>2.363285e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>4.138617e+05</td>\n",
              "      <td>1.988066e+00</td>\n",
              "      <td>1.020891e+02</td>\n",
              "      <td>5.959159e+04</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.558042e-01</td>\n",
              "      <td>6.853256e+01</td>\n",
              "      <td>5.327824e+01</td>\n",
              "      <td>68.695328</td>\n",
              "      <td>1.433425e-01</td>\n",
              "      <td>412.173722</td>\n",
              "      <td>4.720317e+00</td>\n",
              "      <td>3.040914e+00</td>\n",
              "      <td>5.841095e-01</td>\n",
              "      <td>2.042651e+00</td>\n",
              "      <td>1.991992e+00</td>\n",
              "      <td>1.955949e+00</td>\n",
              "      <td>1.895092e+00</td>\n",
              "      <td>1.891116e+00</td>\n",
              "      <td>3.040914e+00</td>\n",
              "      <td>1.963898e+00</td>\n",
              "      <td>1.963990e+00</td>\n",
              "      <td>0.694487</td>\n",
              "      <td>1.664263</td>\n",
              "      <td>4.650350</td>\n",
              "      <td>0.733577</td>\n",
              "      <td>0.147321</td>\n",
              "      <td>133.801658</td>\n",
              "      <td>3.225598e+00</td>\n",
              "      <td>8.180578e+01</td>\n",
              "      <td>4.982939e+00</td>\n",
              "      <td>2.976394e-01</td>\n",
              "      <td>4.513408e-01</td>\n",
              "      <td>4.250063e-01</td>\n",
              "      <td>2.064002e+00</td>\n",
              "      <td>2.298716e-01</td>\n",
              "      <td>2.053198e-01</td>\n",
              "      <td>2.253926e+01</td>\n",
              "      <td>1.235092e-01</td>\n",
              "      <td>3.991710e-01</td>\n",
              "      <td>2.140473e-01</td>\n",
              "      <td>7.138276e-01</td>\n",
              "      <td>6.034020e-01</td>\n",
              "      <td>9.620084e+00</td>\n",
              "      <td>6.029660e+01</td>\n",
              "      <td>8.112179e+00</td>\n",
              "      <td>3.916548e+00</td>\n",
              "      <td>9.844339e+00</td>\n",
              "      <td>3.157169e+01</td>\n",
              "      <td>3.251574e-02</td>\n",
              "      <td>4.805885e-03</td>\n",
              "      <td>7.242642e-03</td>\n",
              "      <td>5.455621e-03</td>\n",
              "      <td>1.897773e-02</td>\n",
              "      <td>2.037183e-03</td>\n",
              "      <td>3.569193e-03</td>\n",
              "      <td>9.911720e-03</td>\n",
              "      <td>8.309291e-04</td>\n",
              "      <td>6.856506e-03</td>\n",
              "      <td>4.083949e-03</td>\n",
              "      <td>1.145421e-02</td>\n",
              "      <td>6.082168e-03</td>\n",
              "      <td>6.285962e-02</td>\n",
              "      <td>2.921248e-01</td>\n",
              "      <td>1.407319e-01</td>\n",
              "      <td>9.083584e-02</td>\n",
              "      <td>4.353711e-02</td>\n",
              "      <td>2.149959e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-1.440000e+03</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>-1.200000e+01</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-145.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3.584160e+05</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>3.000000e+01</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>-5.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>9.928571e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>6.666667e-02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.666667e-01</td>\n",
              "      <td>2.071429e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.166667e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>3.322259e-03</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.612903e-02</td>\n",
              "      <td>2.035398e-01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>6.896552e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>7.168300e+05</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2.100000e+02</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>5.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>232.000000</td>\n",
              "      <td>-3.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.586667e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>6.666667e-02</td>\n",
              "      <td>1.111111e-01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.428571e-01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.428571e-01</td>\n",
              "      <td>7.142857e-02</td>\n",
              "      <td>5.833333e-01</td>\n",
              "      <td>6.666667e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2.166667e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2.427184e-03</td>\n",
              "      <td>5.011390e-03</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>6.896552e-03</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>7.450051e-03</td>\n",
              "      <td>2.824859e-03</td>\n",
              "      <td>3.636364e-02</td>\n",
              "      <td>4.121622e-01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.179245e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.075244e+06</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2.750000e+03</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e+01</td>\n",
              "      <td>6.000000e+00</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>816.000000</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>3.160000e+01</td>\n",
              "      <td>2.857143e-01</td>\n",
              "      <td>1.428571e-01</td>\n",
              "      <td>2.666667e-01</td>\n",
              "      <td>1.428571e-01</td>\n",
              "      <td>3.333333e-01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2.222222e-01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>3.750000e-01</td>\n",
              "      <td>1.428571e-01</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>1.714286e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>5.400000e+00</td>\n",
              "      <td>1.128207e-02</td>\n",
              "      <td>6.711409e-03</td>\n",
              "      <td>9.900990e-03</td>\n",
              "      <td>4.329004e-03</td>\n",
              "      <td>1.161290e-02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.086957e-02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.408451e-02</td>\n",
              "      <td>7.633588e-03</td>\n",
              "      <td>7.216495e-02</td>\n",
              "      <td>6.574074e-01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>4.642857e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.433659e+06</td>\n",
              "      <td>1.800000e+01</td>\n",
              "      <td>2.080800e+04</td>\n",
              "      <td>2.300000e+06</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>5.000000e+02</td>\n",
              "      <td>5.000000e+02</td>\n",
              "      <td>3468.000000</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1678.000000</td>\n",
              "      <td>1.400000e+01</td>\n",
              "      <td>2.400000e+02</td>\n",
              "      <td>5.700000e+01</td>\n",
              "      <td>2.250000e+02</td>\n",
              "      <td>1.960000e+02</td>\n",
              "      <td>2.180000e+02</td>\n",
              "      <td>2.170000e+02</td>\n",
              "      <td>2.170000e+02</td>\n",
              "      <td>2.400000e+02</td>\n",
              "      <td>2.200000e+02</td>\n",
              "      <td>2.200000e+02</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>189.000000</td>\n",
              "      <td>193.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>0.994624</td>\n",
              "      <td>6618.000000</td>\n",
              "      <td>1.748000e+03</td>\n",
              "      <td>3.555370e+04</td>\n",
              "      <td>4.131538e+02</td>\n",
              "      <td>3.500000e+01</td>\n",
              "      <td>3.900000e+01</td>\n",
              "      <td>1.500000e+01</td>\n",
              "      <td>1.970000e+02</td>\n",
              "      <td>5.620000e+01</td>\n",
              "      <td>2.022000e+02</td>\n",
              "      <td>1.243900e+04</td>\n",
              "      <td>1.930435e+01</td>\n",
              "      <td>3.700000e+01</td>\n",
              "      <td>8.740000e+01</td>\n",
              "      <td>1.151600e+02</td>\n",
              "      <td>2.380000e+02</td>\n",
              "      <td>6.360000e+02</td>\n",
              "      <td>3.096035e+04</td>\n",
              "      <td>1.016692e+03</td>\n",
              "      <td>7.908333e+02</td>\n",
              "      <td>3.622630e+03</td>\n",
              "      <td>1.228146e+04</td>\n",
              "      <td>5.625000e-01</td>\n",
              "      <td>1.339713e-01</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.052632e-01</td>\n",
              "      <td>6.403712e-01</td>\n",
              "      <td>1.336016e-01</td>\n",
              "      <td>9.634077e-01</td>\n",
              "      <td>9.991693e-01</td>\n",
              "      <td>1.032733e-01</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>3.216080e-01</td>\n",
              "      <td>4.780702e-01</td>\n",
              "      <td>8.019551e-01</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>9.885057e-01</td>\n",
              "      <td>1.000000e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         account_id  churn_reason  ...  P_event_by_desktop  P_event_by_empty\n",
              "count  1.433661e+06  1.433661e+06  ...        1.433219e+06      1.433219e+06\n",
              "mean   7.168299e+05  2.598160e-01  ...        3.610412e-03      2.363285e-01\n",
              "std    4.138617e+05  1.988066e+00  ...        4.353711e-02      2.149959e-01\n",
              "min    1.000000e+00  0.000000e+00  ...        0.000000e+00      0.000000e+00\n",
              "25%    3.584160e+05  0.000000e+00  ...        0.000000e+00      6.896552e-02\n",
              "50%    7.168300e+05  0.000000e+00  ...        0.000000e+00      1.179245e-01\n",
              "75%    1.075244e+06  0.000000e+00  ...        0.000000e+00      4.642857e-01\n",
              "max    1.433659e+06  1.800000e+01  ...        9.885057e-01      1.000000e+00\n",
              "\n",
              "[8 rows x 68 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMEWXPofVXQp",
        "colab_type": "text"
      },
      "source": [
        "###Re-splitting\n",
        "We now need to split our data back to the original train set and test set.\n",
        "\n",
        "We also make sure we keep only the columns we want in the data frame (the features)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2u-ghg6VsuF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Getting only the relevant features from the dataset\n",
        "dataset = all_features[categorical_features + normalized_features + binary_features + untouched_features + target]\n",
        "\n",
        "# Filling empty values with default values \n",
        "dataset.loc[:,categorical_features] = dataset[categorical_features].fillna('')\n",
        "dataset.loc[:,normalized_features +\n",
        "              binary_features +\n",
        "              untouched_features] = dataset[normalized_features +\n",
        "                                            binary_features +\n",
        "                                            untouched_features].fillna(0)\n",
        "\n",
        "# Splitting them back up to the original train/test split\n",
        "dataset_train = dataset[dataset.reset_index().account_id.isin(train_accounts.account_id)]\n",
        "dataset_test = dataset[dataset.reset_index().account_id.isin(test_accounts.account_id)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3F7pS0pT7Wb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting them back up to the original train/test split\n",
        "dataset_train = dataset.loc[~(dataset['lead_score'].isna())].reset_index().drop(['index'],axis=1)\n",
        "dataset_test = dataset.loc[(dataset['lead_score'].isna())].reset_index().drop(['index'],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IM1ooT2BQtTE",
        "colab_type": "code",
        "outputId": "46109e12-76b8-4cb8-c59b-8ab0b5725c7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset_test[dataset_test['lead_score'].isna()].shape,dataset[dataset['lead_score'].isna()].shape"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((71683, 79), (71683, 79))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeYB9q5Hmdtl",
        "colab_type": "text"
      },
      "source": [
        "###Setting everything up\n",
        "Our dataset is large (1,500,000+ accounts, each has a few users, each has events for every day)\n",
        "\n",
        "We need to work on a smaller batch of the training data so we can iterate more quickly.\n",
        "\n",
        "Once we find a good architecture we can increase the sample size to increase the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kt2uv6bbVVom",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sampled_dataset_train = dataset_train.iloc[sample_without_replacement(dataset_train.shape[0], samples_num)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oOxDhLgM8a4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# You now need to split the data into YOUR OWN training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=42)\n",
        "\n",
        "# For standardization purposes we store y_test in a y_true variable\n",
        "y_true = y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h49yMjV2HMow",
        "colab_type": "code",
        "outputId": "c994fe44-aeb5-4695-d3b2-1ec79da64de8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        }
      },
      "source": [
        "## (when using google colab)\n",
        "! pip install catboost\n",
        "! pip install plotly_express"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.6/dist-packages (0.16.5)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.16.4)\n",
            "Requirement already satisfied: pandas>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from catboost) (0.24.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.1.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.0.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.12.0)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.1->catboost) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.1->catboost) (2.5.3)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (41.2.0)\n",
            "Requirement already satisfied: plotly_express in /usr/local/lib/python3.6/dist-packages (0.4.1)\n",
            "Requirement already satisfied: pandas>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from plotly_express) (0.24.2)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.6/dist-packages (from plotly_express) (0.5.1)\n",
            "Requirement already satisfied: plotly>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from plotly_express) (4.1.1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from plotly_express) (0.10.1)\n",
            "Requirement already satisfied: scipy>=0.18 in /usr/local/lib/python3.6/dist-packages (from plotly_express) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from plotly_express) (1.16.4)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.20.0->plotly_express) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.20.0->plotly_express) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.5->plotly_express) (1.12.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly>=4.1.0->plotly_express) (1.3.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khj17scYHQnH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## General\n",
        "import os \n",
        "import joblib\n",
        "import requests\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "\n",
        "## Data manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "## Modeling\n",
        "### Modeling pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        " \n",
        "### Models\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier    \n",
        "from catboost import CatBoostClassifier, Pool\n",
        "\n",
        "## Visuatlization\n",
        "import plotly \n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lU_fiOvFHE0p",
        "colab_type": "code",
        "outputId": "f77df6d4-876f-459a-e18c-21c1f0e97be8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "parameters = {'n_estimators': [50], #[50,100,200]\n",
        "             'max_depth': [5], #[5,10,15],\n",
        "             'criterion': ['gini', 'entropy'],\n",
        "             'max_features': [15]} #[int(np.log2(X_train.shape[1])), int(np.sqrt(X_train.shape[1]))]\n",
        "\n",
        "rf_cv = GridSearchCV(RandomForestClassifier(class_weight='balanced'), \n",
        "                   parameters, \n",
        "                   n_jobs = -1,\n",
        "                   cv = 5,\n",
        "                   refit = True,\n",
        "                   scoring = 'f1')\n",
        "\n",
        "rf_cv.fit(X_train, y_train)"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
              "             estimator=RandomForestClassifier(bootstrap=True,\n",
              "                                              class_weight='balanced',\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features='auto',\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              n_estimators='warn', n_jobs=None,\n",
              "                                              oob_score=False,\n",
              "                                              random_state=None, verbose=0,\n",
              "                                              warm_start=False),\n",
              "             iid='warn', n_jobs=-1,\n",
              "             param_grid={'criterion': ['gini', 'entropy'], 'max_depth': [5],\n",
              "                         'max_features': [15], 'n_estimators': [50]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='f1', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 206
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQDz6eEvcGLJ",
        "colab_type": "code",
        "outputId": "2d86a567-a502-4fbc-cfef-30369d07ab87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "rf_best_model = rf_cv.best_estimator_\n",
        "rf_best_model"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
              "                       criterion='entropy', max_depth=5, max_features=15,\n",
              "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
              "                       min_impurity_split=None, min_samples_leaf=1,\n",
              "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
              "                       n_estimators=50, n_jobs=None, oob_score=False,\n",
              "                       random_state=None, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QW73bMecL9F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_pred = rf_best_model.predict(X_train) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nReMIThzcPnk",
        "colab_type": "code",
        "outputId": "816713ba-9bf2-43fb-aab6-e3288a761321",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "accuracy_score(y_train_pred, y_train),f1_score(y_train, y_train_pred),precision_score(y_train, y_train_pred),recall_score(y_train, y_train_pred)"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8573374613003096,\n",
              " 0.25021966220833736,\n",
              " 0.14390522355935692,\n",
              " 0.9578921141148623)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFMf9ez3cgo8",
        "colab_type": "code",
        "outputId": "072b9e94-12e1-4f0e-cade-44aea16138d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "confusion_matrix(y_train_pred, y_train)\n",
        "\n"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1083755,    1362],\n",
              "       [ 176137,   30746]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeEMwslgdJGF",
        "colab_type": "text"
      },
      "source": [
        "## XGBOOST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-8dISHGdaan",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "parameters = {\n",
        "    \"gamma\": [0.2, 0.5],\n",
        "    \"learning_rate\": [0.1]\n",
        "}\n",
        "\n",
        "xgb_cv = GridSearchCV(XGBClassifier(class_weight='balanced'), \n",
        "                       parameters, \n",
        "                       n_jobs = -1,\n",
        "                       cv = 5,\n",
        "                       refit = True,\n",
        "                       scoring = 'f1')\n",
        "\n",
        "xgb_cv.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAf6E5EPdeSd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xgb_best_model = xgb_cv.best_estimator_\n",
        "xgb_best_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NxU4CAwdiES",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_pred = xgb_best_model.predict(X_train) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9C0eQoiqNgrU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy_score(y_train_pred, y_train),f1_score(y_train, y_train_pred),precision_score(y_train, y_train_pred),recall_score(y_train, y_train_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbxKBGRSeFV_",
        "colab_type": "text"
      },
      "source": [
        "## Catboost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYC1FLLWeVsE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parameters = {\n",
        "    \"reg_lambda\": [0, 0.2, 0.5],\n",
        "    \"learning_rate\": [0.1],\n",
        "    \"loss_function\": ['Logloss'] #F1, recall, ... \n",
        "}\n",
        "\n",
        "cat_cv = GridSearchCV(CatBoostClassifier(class_weights = [0.98, 0.02]), \n",
        "                       parameters, \n",
        "                       n_jobs = -1,\n",
        "                       cv = 5,\n",
        "                       refit = True,\n",
        "                       scoring = 'f1',\n",
        "                       verbose = 0)\n",
        "\n",
        "cat_cv.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJs7Ngnao4nC",
        "colab_type": "text"
      },
      "source": [
        "###Running the model\n",
        "It's the money time, we can finally run our model!\n",
        "\n",
        "First we need to created it, and train(fit) it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-H91z01wwlI",
        "colab_type": "code",
        "outputId": "46d62a67-c4a4-4378-ac2d-c1d763b9a0e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Now we need to get the predictions of our test set\n",
        "%time y_pred = rf_best_model.predict(X_test)"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 274 ms, sys: 2.01 ms, total: 276 ms\n",
            "Wall time: 276 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HNTLiSgpn1W",
        "colab_type": "text"
      },
      "source": [
        "###Model evaluation\n",
        "Now that we have our model and it can predict the lead score based on features, we need a way to test if it's any good"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wglP_6UqOq_",
        "colab_type": "text"
      },
      "source": [
        "####Classification report\n",
        "We use classification_report to get different metrics comparing our prediction to the ground truth."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpmyj4P-flpW",
        "colab_type": "code",
        "outputId": "cb090fd0-d854-4b79-ac1c-7ba6562e3bf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "print(classification_report(y_true, y_pred, target_names=['Not Lead', 'Lead']))"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Not Lead       1.00      0.86      0.92     66270\n",
            "        Lead       0.15      0.96      0.26      1730\n",
            "\n",
            "    accuracy                           0.86     68000\n",
            "   macro avg       0.58      0.91      0.59     68000\n",
            "weighted avg       0.98      0.86      0.91     68000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGt_gAIt5iqF",
        "colab_type": "text"
      },
      "source": [
        "We can also get the MCC score of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_Ax24kc5dgq",
        "colab_type": "code",
        "outputId": "207d0ad7-5084-4366-c9b7-ffa523605829",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "print('Acc:  {}'.format(metrics.accuracy_score(y_true, y_pred)))\n",
        "print('MCC: {}'.format(metrics.matthews_corrcoef(y_true, y_pred)))\n",
        "print('F1:  {}'.format(metrics.f1_score(y_true, y_pred)))"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acc:  0.862985294117647\n",
            "MCC: 0.3505527241635424\n",
            "F1:  0.26201980198019803\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0CC280TpnGV",
        "colab_type": "text"
      },
      "source": [
        "####Plotting the confusion matrix\n",
        "Confusion matrices are useful for comparing our predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRd1YjZFy-UJ",
        "colab_type": "code",
        "outputId": "e836b963-5cc2-4ee1-8374-06f95203ec30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "fig, axs = plt.subplots(ncols=2, figsize=(14,4))\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "ticks = ['Not Lead', 'Lead']\n",
        "cmap = sns.color_palette(\"Blues\")\n",
        "\n",
        "# We normalize our data to see more accurate comparsion\n",
        "sns.heatmap(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], annot=True, ax=axs[0], cmap=cmap)\n",
        "axs[0].set(title=\"Normalized confusion matrix\", xlabel=\"Prediction\", ylabel=\"Truth\", xticklabels=ticks, yticklabels=ticks)\n",
        "\n",
        "# We also plot the original numbers to get the whole picture\n",
        "sns.heatmap(cm, annot=True, ax=axs[1], fmt='g', cmap=cmap)\n",
        "axs[1].set(title=\"Confusion matrix\", xlabel=\"Prediction\", ylabel=\"Truth\", xticklabels=ticks, yticklabels=ticks);"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzYAAAEWCAYAAAC0fAJeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsTEzMzMzs5LnxMbMzMzMzEre/wPMpye4CUPK/wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1008x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FUIBac_ZRLp",
        "colab_type": "text"
      },
      "source": [
        "###Submitting results\n",
        "After you ran several iterations, and you think your model is good enough, you can send it to us and we'll add your score on the leaderboard!\n",
        "\n",
        "You have to get the results into the following format:\n",
        "```python\n",
        "{\"9023749\": 1, \"9837598\": 0, ...}\n",
        "```\n",
        "\n",
        "This is a dictionary where the keys are `account_id`s and the values are the predicted lead_score.\n",
        "\n",
        "_Make sure you send us **all** the test accounts!_\n",
        "\n",
        "_There should be exactly `71,683` of them!_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmB5Vx91ao4t",
        "colab_type": "text"
      },
      "source": [
        "####Prediction\n",
        "First of all, just like before, we have to predict the lead_score.\n",
        "\n",
        "This time you need to use the test set _we_ provided."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xv469ucaoJ-",
        "colab_type": "code",
        "outputId": "73ae892e-8443-4427-d3f9-a022ff6a0ad2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "dataset_test = dataset[dataset['lead_score'].isna()]\n",
        "submission_account_ids = dataset_test.account_id\n",
        "\n",
        "X_submission = preprocess.transform(dataset_test)\n",
        "\n",
        "y_pred_submission = rf_best_model.predict(X_submission)"
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFittedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-212-8c5c2cfab048>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msubmission_account_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccount_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX_submission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my_pred_submission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf_best_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_submission\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m         \"\"\"\n\u001b[0;32m--> 517\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'transformers_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFittedError\u001b[0m: This ColumnTransformer instance is not fitted yet. Call 'fit' with appropriate arguments before using this method."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQnIWRVbcltE",
        "colab_type": "text"
      },
      "source": [
        "####Submission\n",
        "Now that we have our submission predictions, we need to pack them up into a compatible format for our server to handle.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFfuM8ve8t1w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a dictionary where the keys are the account_ids\n",
        "# and the values are your predictions\n",
        "prediction = dict(zip(map(str, map(int,submission_account_ids)), map(int,y_pred_submission)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltQWs9SEP89a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdlT5SRJdadv",
        "colab_type": "text"
      },
      "source": [
        "We now just send the results to our server and wait for the score!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1Ev6lafdZoJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing stuff for http requests\n",
        "from urllib import request\n",
        "import json\n",
        "\n",
        "# We validate first that we actually send all the test accounts expected to be sent\n",
        "if y_pred_submission.shape[0] != 71683 or submission_account_ids.shape[0] != 71683:\n",
        "  raise Exception(\"You have to send all of the accounts! Expected: (71683, 71683), Got: ({}, {})\".format(y_pred_submission.shape[0], submission_account_ids.shape[0]))\n",
        "\n",
        "if \"group_name\" not in vars() or group_name == \"\":\n",
        "  group_name = input(\"Please enter your group's name:\")\n",
        "\n",
        "data = json.dumps({'submitter': group_name, 'predictions': prediction}).encode('utf-8')\n",
        "\n",
        "req = request.Request(f\"https://leaderboard.datahack.org.il/monday/api/\",\n",
        "                      headers={'Content-Type': 'application/json'},\n",
        "                      data=data)\n",
        "\n",
        "res = request.urlopen(req)\n",
        "print(json.load(res))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}